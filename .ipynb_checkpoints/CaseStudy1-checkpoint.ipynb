{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study 1 : Collecting Data from Twitter\n",
    "\n",
    "Due Date: September 22, **before the beginning of class at 6:00pm**\n",
    "\n",
    "* ------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/en/thumb/9/9f/Twitter_bird_logo_2012.svg/220px-Twitter_bird_logo_2012.svg.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TEAM Members:**\n",
    "\n",
    "    Matthew Beaulieu\n",
    "    \n",
    "    Yousef Fadila\n",
    "    \n",
    "    Meng Li\n",
    "    \n",
    "    Monica Tlachac\n",
    "    \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Required Readings:** \n",
    "* Chapter 1 and Chapter 9 of the book [Mining the Social Web](http://www.learndatasci.com/wp-content/uploads/2015/08/Mining-the-Social-Web-2nd-Edition.pdf) \n",
    "* The codes for [Chapter 1](http://bit.ly/1qCtMrr) and [Chapter 9](http://bit.ly/1u7eP33)\n",
    "\n",
    "\n",
    "** NOTE **\n",
    "* Please don't forget to save the notebook frequently when working in IPython Notebook, otherwise the changes you made can be lost.\n",
    "\n",
    "*----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Sampling Twitter Data with Streaming API about a certain topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Select a topic that you are interested in, for example, \"WPI\" or \"Lady Gaga\"\n",
    "* Use Twitter Streaming API to sample a collection of tweets about this topic in real time. (It would be recommended that the number of tweets should be larger than 200, but smaller than 1 million.\n",
    "* Store the tweets you downloaded into a local file (txt file or json file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import warnings\n",
    "import json\n",
    "import numpy as np\n",
    "import wikiwords\n",
    "from tweepy import Stream\n",
    "from tweepy.streaming import StreamListener\n",
    "import pymongo\n",
    "import tweepy\n",
    "\n",
    "warnings.simplefilter(action = \"ignore\", category = FutureWarning)\n",
    "%matplotlib inline\n",
    "#---------------------------------------------\n",
    "# Define a Function to Login Twitter API\n",
    "#\n",
    "# XXX  - DON'T COMMIT TRUE CREDINTIALS TO GITHUB\n",
    "#CONSUMER_KEY = 'k01qrrsDSOHdjUObbt1pWjhld'\n",
    "#CONSUMER_SECRET ='FTBSa4UU5Nxaw00hNPJQvoAf60HinJM87GfQpuFM0YsVKDdoJD'\n",
    "#OAUTH_TOKEN = '4229853605-mSgVKfVSZ9BSN7GbPgvUIPOT1Xl6F3nA2ynKMvy'\n",
    "#OAUTH_TOKEN_SECRET = 'jyHtNVKGmqNw4HyBLMYG5i9BT3junKGVFnY6CE2tjJRFW'\n",
    "\n",
    "# another set of auth to use when limit is hit.\n",
    "CONSUMER_KEY = '7n45AnattFU5sb3MpbiwIoNYF'\n",
    "CONSUMER_SECRET ='VtnEmlR99dG3hQ8FP8xb1TnomTAjSGkQYDJVhGa28IDPDEA2Cf'\n",
    "OAUTH_TOKEN = '2497861306-W7d3EXegd4AY6jYt9ZaEz5rq5ZtguAAtp6KbseS'\n",
    "OAUTH_TOKEN_SECRET = 'uv71S6pJwPibOFLA8WetoxWRb0nfqcQPK8f3ts30nEfQT'\n",
    "\n",
    "# mango db auth.\n",
    "MANGODB_SERVER = 'ds033046.mlab.com'\n",
    "MANGODB_PORT = 33046\n",
    "MANGODB_USER = 'ds501u'\n",
    "MANGODB_PASS = 'ds501p'\n",
    "MANGODB_NAME = 'ds501case1'\n",
    "MANGODB_COLLECTION = 'tweets'\n",
    "GEOBOX_USA = [-125,25.1,-60.5,49.1]\n",
    "\n",
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(OAUTH_TOKEN, OAUTH_TOKEN_SECRET)\n",
    "\n",
    "#----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "streaming done - limit: 1\n"
     ]
    }
   ],
   "source": [
    "class MyListener(StreamListener):\n",
    "    def __init__(self, max_count = 100):\n",
    "        self.count = 0\n",
    "        self.max_count = max_count\n",
    "        db_client = pymongo.MongoClient(MANGODB_SERVER, MANGODB_PORT)\n",
    "        db = db_client[MANGODB_NAME]\n",
    "        db.authenticate(MANGODB_USER, MANGODB_PASS)      \n",
    "        self.collection = db[MANGODB_COLLECTION]\n",
    "\n",
    "    def on_data(self, data):\n",
    "        try:\n",
    "            if self.count >= self.max_count:\n",
    "                return False\n",
    "            # the question require output to file. so output to file and save in mangoDB\n",
    "            with open('case1data.json', 'a') as f:\n",
    "                f.write(data)\n",
    "            self.count = self.count + 1\n",
    "            datajson = json.loads(data)\n",
    "            self.collection.insert_one(datajson)\n",
    "            return True\n",
    "        except BaseException as e:\n",
    "            print(e)\n",
    "        return True\n",
    " \n",
    "    def on_error(self, status):\n",
    "        print(status)\n",
    "        return True\n",
    "    \n",
    "api = tweepy.API(auth)\n",
    "limit = 1\n",
    "twitter_stream = Stream(auth, MyListener(limit))\n",
    "twitter_stream.filter(track=['@HillaryClinton'], languages=[\"en\"], locations=GEOBOX_USA)\n",
    "print(\"streaming done - limit: \" + str(limit))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# example how to get the state from the tweet.\n",
    "lst = []\n",
    "states = []\n",
    "with open('data/hillary.json', 'r') as f:\n",
    "    for line in f:\n",
    "        tweet = json.loads(line)\n",
    "        lst.append(tweet)\n",
    "\n",
    "states = [tweeet['place']['full_name'].split()\n",
    "         for tweeet in lst if tweeet['place']]\n",
    "\n",
    "states = [x[len(x) - 1] for x in states if x[(len(x) - 1)] != 'USA']      \n",
    "df = pd.DataFrame(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lis = []\n",
    "with open('hillary.json', 'r') as f:\n",
    "    for line in f:\n",
    "        tweet = json.loads(line)\n",
    "        lis.append(tweet) # load it as Python dict\n",
    "\n",
    "with open('hillary2.json', 'r') as f:\n",
    "    for line in f:\n",
    "        tweet = json.loads(line)\n",
    "        lis.append(tweet) # load it as Python dict\n",
    "    \n",
    "df = pd.DataFrame(lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we already filter english in streaming\n",
    "# TODO ; use the function described in lecture to filter out english common words.\n",
    "#df = df[df['lang'] == 'en']\n",
    "text = df.text.str.lower()\n",
    "for i,t in enumerate(text):\n",
    "    new = ''.join(e for e in t if (e.isalnum() or e==' '))\n",
    "    text[i] = new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = text.str.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word_dict = {}\n",
    "for r in range(text.shape[0]):\n",
    "    lis = text.values[r]\n",
    "    for word in lis:\n",
    "        if word in word_dict.keys():\n",
    "            word_dict[word] +=1\n",
    "        else:\n",
    "            word_dict[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vals = []\n",
    "for key in word_dict.keys():\n",
    "    vals.append(word_dict.get(key))\n",
    "    \n",
    "tweet_df = pd.DataFrame({'words':list(word_dict.keys()), 'vals':vals})\n",
    "tweet_df = tweet_df.sort_values('vals', ascending=False)\n",
    "tweet_df['freq'] = tweet_df['words'].apply(wikiwords.freq)\n",
    "tweet_df = tweet_df[tweet_df['freq'] > 1.0e-6]\n",
    "tweet_df['ratio'] = tweet_df['vals'] / tweet_df['freq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vals</th>\n",
       "      <th>words</th>\n",
       "      <th>freq</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6578</th>\n",
       "      <td>7985</td>\n",
       "      <td>rt</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>9.576719e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16976</th>\n",
       "      <td>1014</td>\n",
       "      <td>https</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>3.553047e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15423</th>\n",
       "      <td>966</td>\n",
       "      <td>amp</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>2.643970e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13350</th>\n",
       "      <td>391</td>\n",
       "      <td>hypocrisy</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2.041077e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>992</td>\n",
       "      <td>trump</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1.671781e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11184</th>\n",
       "      <td>897</td>\n",
       "      <td>hillary</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1.627810e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14071</th>\n",
       "      <td>177</td>\n",
       "      <td>politico</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.535317e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11987</th>\n",
       "      <td>236</td>\n",
       "      <td>unfit</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.062605e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6602</th>\n",
       "      <td>104</td>\n",
       "      <td>yells</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.025306e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12421</th>\n",
       "      <td>290</td>\n",
       "      <td>stunning</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>8.027490e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12701</th>\n",
       "      <td>97</td>\n",
       "      <td>yrs</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>7.345456e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7281</th>\n",
       "      <td>115</td>\n",
       "      <td>bodyguards</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>7.057417e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10584</th>\n",
       "      <td>81</td>\n",
       "      <td>benghazi</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>6.408022e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15624</th>\n",
       "      <td>207</td>\n",
       "      <td>doesnt</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.278809e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3828</th>\n",
       "      <td>268</td>\n",
       "      <td>cant</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>6.045840e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13655</th>\n",
       "      <td>54</td>\n",
       "      <td>dnc</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>5.170405e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7605</th>\n",
       "      <td>94</td>\n",
       "      <td>didnt</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>5.126433e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14233</th>\n",
       "      <td>86</td>\n",
       "      <td>trumps</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>4.904659e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12671</th>\n",
       "      <td>94</td>\n",
       "      <td>wont</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>4.811936e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5632</th>\n",
       "      <td>108</td>\n",
       "      <td>gop</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>4.373711e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>91</td>\n",
       "      <td>poorest</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>4.258990e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5185</th>\n",
       "      <td>412</td>\n",
       "      <td>lets</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>3.826785e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4816</th>\n",
       "      <td>75</td>\n",
       "      <td>whats</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>3.786318e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2273</th>\n",
       "      <td>104</td>\n",
       "      <td>realises</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>3.763119e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14568</th>\n",
       "      <td>141</td>\n",
       "      <td>liar</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>3.693382e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10773</th>\n",
       "      <td>160</td>\n",
       "      <td>msnbc</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>3.610570e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3961</th>\n",
       "      <td>73</td>\n",
       "      <td>blackmail</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>3.535690e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13949</th>\n",
       "      <td>36</td>\n",
       "      <td>tweet</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.457496e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4645</th>\n",
       "      <td>389</td>\n",
       "      <td>dont</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>3.437822e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11234</th>\n",
       "      <td>148</td>\n",
       "      <td>pneumonia</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>3.434423e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2825</th>\n",
       "      <td>1</td>\n",
       "      <td>cup</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>3.574878e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11277</th>\n",
       "      <td>1</td>\n",
       "      <td>william</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>3.289272e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10835</th>\n",
       "      <td>1</td>\n",
       "      <td>art</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>3.270927e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9539</th>\n",
       "      <td>1</td>\n",
       "      <td>began</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>3.137554e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15474</th>\n",
       "      <td>1</td>\n",
       "      <td>published</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>3.025997e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11749</th>\n",
       "      <td>1</td>\n",
       "      <td>player</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>3.001422e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16506</th>\n",
       "      <td>1</td>\n",
       "      <td>center</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>2.991582e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15418</th>\n",
       "      <td>1</td>\n",
       "      <td>version</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>2.928784e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16692</th>\n",
       "      <td>1</td>\n",
       "      <td>official</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>2.807658e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2947</th>\n",
       "      <td>1</td>\n",
       "      <td>although</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>2.772335e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1360</th>\n",
       "      <td>1</td>\n",
       "      <td>park</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>2.686969e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18562</th>\n",
       "      <td>1</td>\n",
       "      <td>river</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>2.645665e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>2</td>\n",
       "      <td>june</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>2.457578e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14659</th>\n",
       "      <td>2</td>\n",
       "      <td>august</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>2.399358e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12202</th>\n",
       "      <td>1</td>\n",
       "      <td>english</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>2.330509e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18079</th>\n",
       "      <td>1</td>\n",
       "      <td>club</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>2.307582e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13111</th>\n",
       "      <td>1</td>\n",
       "      <td>international</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>2.041028e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12122</th>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.999794e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5482</th>\n",
       "      <td>1</td>\n",
       "      <td>wp</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>1.767946e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15049</th>\n",
       "      <td>1</td>\n",
       "      <td>music</td>\n",
       "      <td>0.000612</td>\n",
       "      <td>1.633569e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9984</th>\n",
       "      <td>1</td>\n",
       "      <td>category</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>1.545078e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19037</th>\n",
       "      <td>3</td>\n",
       "      <td>page</td>\n",
       "      <td>0.002097</td>\n",
       "      <td>1.430515e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8252</th>\n",
       "      <td>1</td>\n",
       "      <td>film</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>1.414307e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4851</th>\n",
       "      <td>1</td>\n",
       "      <td>february</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>1.390241e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10502</th>\n",
       "      <td>1</td>\n",
       "      <td>january</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>1.197539e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>1</td>\n",
       "      <td>university</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>1.186993e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10440</th>\n",
       "      <td>1</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>0.000896</td>\n",
       "      <td>1.115452e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15814</th>\n",
       "      <td>1</td>\n",
       "      <td>diff</td>\n",
       "      <td>0.000927</td>\n",
       "      <td>1.079111e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15934</th>\n",
       "      <td>1</td>\n",
       "      <td>discussion</td>\n",
       "      <td>0.001143</td>\n",
       "      <td>8.747827e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13570</th>\n",
       "      <td>1</td>\n",
       "      <td>links</td>\n",
       "      <td>0.001222</td>\n",
       "      <td>8.182906e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6751 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       vals          words      freq         ratio\n",
       "6578   7985             rt  0.000008  9.576719e+08\n",
       "16976  1014          https  0.000003  3.553047e+08\n",
       "15423   966            amp  0.000004  2.643970e+08\n",
       "13350   391      hypocrisy  0.000002  2.041077e+08\n",
       "1060    992          trump  0.000006  1.671781e+08\n",
       "11184   897        hillary  0.000006  1.627810e+08\n",
       "14071   177       politico  0.000001  1.535317e+08\n",
       "11987   236          unfit  0.000002  1.062605e+08\n",
       "6602    104          yells  0.000001  1.025306e+08\n",
       "12421   290       stunning  0.000004  8.027490e+07\n",
       "12701    97            yrs  0.000001  7.345456e+07\n",
       "7281    115     bodyguards  0.000002  7.057417e+07\n",
       "10584    81       benghazi  0.000001  6.408022e+07\n",
       "15624   207         doesnt  0.000003  6.278809e+07\n",
       "3828    268           cant  0.000004  6.045840e+07\n",
       "13655    54            dnc  0.000001  5.170405e+07\n",
       "7605     94          didnt  0.000002  5.126433e+07\n",
       "14233    86         trumps  0.000002  4.904659e+07\n",
       "12671    94           wont  0.000002  4.811936e+07\n",
       "5632    108            gop  0.000002  4.373711e+07\n",
       "649      91        poorest  0.000002  4.258990e+07\n",
       "5185    412           lets  0.000011  3.826785e+07\n",
       "4816     75          whats  0.000002  3.786318e+07\n",
       "2273    104       realises  0.000003  3.763119e+07\n",
       "14568   141           liar  0.000004  3.693382e+07\n",
       "10773   160          msnbc  0.000004  3.610570e+07\n",
       "3961     73      blackmail  0.000002  3.535690e+07\n",
       "13949    36          tweet  0.000001  3.457496e+07\n",
       "4645    389           dont  0.000011  3.437822e+07\n",
       "11234   148      pneumonia  0.000004  3.434423e+07\n",
       "...     ...            ...       ...           ...\n",
       "2825      1            cup  0.000280  3.574878e+03\n",
       "11277     1        william  0.000304  3.289272e+03\n",
       "10835     1            art  0.000306  3.270927e+03\n",
       "9539      1          began  0.000319  3.137554e+03\n",
       "15474     1      published  0.000330  3.025997e+03\n",
       "11749     1         player  0.000333  3.001422e+03\n",
       "16506     1         center  0.000334  2.991582e+03\n",
       "15418     1        version  0.000341  2.928784e+03\n",
       "16692     1       official  0.000356  2.807658e+03\n",
       "2947      1       although  0.000361  2.772335e+03\n",
       "1360      1           park  0.000372  2.686969e+03\n",
       "18562     1          river  0.000378  2.645665e+03\n",
       "328       2           june  0.000814  2.457578e+03\n",
       "14659     2         august  0.000834  2.399358e+03\n",
       "12202     1        english  0.000429  2.330509e+03\n",
       "18079     1           club  0.000433  2.307582e+03\n",
       "13111     1  international  0.000490  2.041028e+03\n",
       "12122     1           west  0.000500  1.999794e+03\n",
       "5482      1             wp  0.000566  1.767946e+03\n",
       "15049     1          music  0.000612  1.633569e+03\n",
       "9984      1       category  0.000647  1.545078e+03\n",
       "19037     3           page  0.002097  1.430515e+03\n",
       "8252      1           film  0.000707  1.414307e+03\n",
       "4851      1       february  0.000719  1.390241e+03\n",
       "10502     1        january  0.000835  1.197539e+03\n",
       "3485      1     university  0.000842  1.186993e+03\n",
       "10440     1      wikipedia  0.000896  1.115452e+03\n",
       "15814     1           diff  0.000927  1.079111e+03\n",
       "15934     1     discussion  0.001143  8.747827e+02\n",
       "13570     1          links  0.001222  8.182906e+02\n",
       "\n",
       "[6751 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df.sort_values('ratio', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9396"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report some statistics about the tweets you collected \n",
    "\n",
    "* The topic of interest: < INSERT YOUR TOPIC HERE>\n",
    "\n",
    "\n",
    "* The total number of tweets collected:  < INSERT THE NUMBER HERE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import folium\n",
    "import pandas as pd\n",
    "from IPython.display import HTML\n",
    "\n",
    "def display(m, height=500):\n",
    "    m.save(\"DS501map.html\")\n",
    "    get_html = m._repr_html_()\n",
    "    s=get_html.replace('\"', '&quot;')\n",
    "    embed = HTML('<iframe srcdoc=\"{0}\" '\n",
    "                 'style=\"width: 100%; height: {1}px; '\n",
    "                 'border: none\"></iframe>'.format(s, height))\n",
    "    return embed\n",
    "state_geo = r'us-states.json'\n",
    "clinton_popularity_str = '{\"WA\": 7.8, \"DE\": 7.1, \"WI\": 6.8, \"WV\": 7.5, \"HI\": 5.4, \"FL\": 8.2, \"WY\": 5.1, \"NH\": 5.7, \"NJ\": 9.6, \"NM\": 6.8, \"TX\": 10, \"LA\": 5.9, \"NC\": 9.4, \"ND\": 3.2, \"NE\": 3.9, \"TN\": 7.8, \"NY\": 8.4, \"PA\": 8.0, \"CA\": 10.1, \"NV\": 10.3, \"VA\": 5.8, \"CO\": 7.7, \"AK\": 6.8, \"AL\": 7.1, \"AR\": 7.2, \"VT\": 5.0, \"IL\": 8.8, \"GA\": 8.8, \"IN\": 8.4, \"IA\": 5.1, \"OK\": 5.2, \"AZ\": 8.1, \"ID\": 6.6, \"CT\": 8.4, \"ME\": 7.2, \"MD\": 6.8, \"MA\": 6.7, \"OH\": 6.9, \"UT\": 5.5, \"MO\": 6.7, \"MN\": 5.6, \"MI\": 9.1, \"RI\": 10.1, \"KS\": 5.6, \"MT\": 5.8, \"MS\": 9.1, \"SC\": 8.8, \"KY\": 8.1, \"OR\": 8.5, \"SD\": 4.4}' \n",
    "clinton_popularity_json = json.loads(clinton_popularity_str)\n",
    "\n",
    "map = folium.Map(location=(39, -100), zoom_start=4)\n",
    "#map = folium.Map(location=[48, -102], zoom_start=3)\n",
    "map.choropleth(geo_path=state_geo, data=clinton_popularity_json,\n",
    "             key_on='feature.id',\n",
    "             fill_color='BuPu', fill_opacity=0.8, line_opacity=0.6,\n",
    "             reset=False)\n",
    "print (\"the map should be shown below; if you can't see it, please find it in DS501map.html or re-run the cell\")\n",
    "display(map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Analyzing Tweets and Tweet Entities with Frequency Analysis\n",
    "\n",
    "**1. Word Count:** \n",
    "* Use the tweets you collected in Problem 1, and compute the frequencies of the words being used in these tweets. \n",
    "* Plot a table of the top 30 words with their counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Find the most popular tweets in your collection of tweets**\n",
    "\n",
    "Please plot a table of the top 10 tweets that are the most popular among your collection, i.e., the tweets with the largest number of retweet counts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Find the most popular Tweet Entities in your collection of tweets**\n",
    "\n",
    "Please plot a table of the top 10 hashtags, top 10 user mentions that are the most popular in your collection of tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ------------------------\n",
    "\n",
    "# Problem 3: Getting \"All\" friends and \"All\" followers of a popular user in twitter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* choose a popular twitter user who has many followers, such as \"ladygaga\".\n",
    "* Get the list of all friends and all followers of the twitter user.\n",
    "* Plot 20 out of the followers, plot their ID numbers and screen names in a table.\n",
    "* Plot 20 out of the friends (if the user has more than 20 friends), plot their ID numbers and screen names in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#definitios and config values\n",
    "\n",
    "# As HillaryClinton has million of followers, we would use wait_on_rate_limit to fetch all of her friends. \n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True, compression=True)\n",
    "#api = tweepy.API(auth)\n",
    "\n",
    "MANGODB_SERVER = 'ds035776.mlab.com'\n",
    "MANGODB_PORT = 35776\n",
    "MANGODB_CLINTON_FF_DB_NAME = \"clinton_followers_friends\"\n",
    "MANGODB_CLINTON_FF_COLL = \"collection\"\n",
    "db_clinton_ff_client = pymongo.MongoClient(MANGODB_SERVER, MANGODB_PORT)\n",
    "db_clinton_ff = db_clinton_ff_client[MANGODB_CLINTON_FF_DB_NAME]\n",
    "db_clinton_ff.authenticate(MANGODB_USER, MANGODB_PASS)  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 899\n"
     ]
    }
   ],
   "source": [
    "# fetch up to 200000\n",
    "# to fetch all followers \n",
    "# call the API with \n",
    "#tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True, compression=True)\n",
    "# and removethe .items(200000);\n",
    "\n",
    "data_followers = {}\n",
    "data_followers['type'] = 'followers'\n",
    "data_followers['lst'] = []\n",
    "\n",
    "for itm in tweepy.Cursor(api.followers_ids, id = 'HillaryClinton').items(200000):\n",
    "    data_followers['lst'].append(itm)\n",
    "\n",
    "# save the followers's list in mangoDB    \n",
    "followers_json = json.loads(json.dumps(data_followers))\n",
    "db_clinton_ff[MANGODB_CLINTON_FF_COLL].insert_one(followers_json)\n",
    "\n",
    "\n",
    "data_friends = {}\n",
    "data_friends['type'] = 'friends'\n",
    "data_friends['lst'] = []\n",
    "\n",
    "# fetch all friends list - as this list relativly samll we won't hit the limit here.\n",
    "\n",
    "friends_ids = []     \n",
    "for itm in tweepy.Cursor(api.friends_ids, id = 'HillaryClinton'):\n",
    "    data_friends['lst'].append(itm)\n",
    "\n",
    "# save the friend's list in mangoDB    \n",
    "friends_json = json.loads(json.dumps(data_friends))  \n",
    "db_clinton_ff[MANGODB_CLINTON_FF_COLL].insert_one(friends_json)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "# Given a set of user ids, this function calls get_screen_names and plots a table of the first (max_ids) ID's and screen names.\n",
    "def draw_pretty_table(ids):\n",
    "    users = api.lookup_users(user_ids=ids)\n",
    "    pretty_table = PrettyTable(['ID','Screen Name'])\n",
    "    [pretty_table.add_row ([row.id,row.screen_name]) for row in users]\n",
    "    pretty_table.align = 'l'\n",
    "    print(pretty_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "20 friends of Hilary Clinton\n",
      "\n",
      "+--------------------+----------------+\n",
      "| ID                 | Screen Name    |\n",
      "+--------------------+----------------+\n",
      "| 571202103          | Medium         |\n",
      "| 21337440           | ChildDefender  |\n",
      "| 23449384           | amberdiscko    |\n",
      "| 128790234          | Samynemir      |\n",
      "| 1656913327         | sarajacobs89   |\n",
      "| 325886383          | SammyKoppelman |\n",
      "| 802430450          | Natasha_S_Law  |\n",
      "| 729761993461248000 | ktvibbs        |\n",
      "| 115740215          | SarahAudelo    |\n",
      "| 34782406           | Lincoln_Ross   |\n",
      "| 3044781131         | HillaryforAR   |\n",
      "| 113298560          | GunaRockYa     |\n",
      "| 15972271           | CdotDukes      |\n",
      "| 582037089          | MiguelAyala312 |\n",
      "| 734768872625188864 | AndrewBatesNC  |\n",
      "| 41021335           | TroyClair      |\n",
      "| 4736170399         | BrianZuzenak   |\n",
      "| 150885854          | SarahPeckVA    |\n",
      "| 231673             | yianni         |\n",
      "| 125083946          | GillDrummond   |\n",
      "+--------------------+----------------+\n",
      "\n",
      "20 followers of Hilary Clinton\n",
      "\n",
      "+--------------------+-----------------+\n",
      "| ID                 | Screen Name     |\n",
      "+--------------------+-----------------+\n",
      "| 778164367237996544 | asdfsaorhdajgj3 |\n",
      "| 778159354205921280 | lexempireng     |\n",
      "| 778161847316914178 | MhzMuhsin       |\n",
      "| 741839179374419968 | RLf7s20oxchkEkD |\n",
      "| 778162986556985344 | McgivenJulia    |\n",
      "| 778164330718265344 | Muncheros86     |\n",
      "| 3412437837         | BonnieW86051174 |\n",
      "| 321312441          | nasrpipeng      |\n",
      "| 77751179           | ker84           |\n",
      "| 778164201529499648 | TwanasShop      |\n",
      "| 778163663836413955 | Naveed23559443  |\n",
      "| 778164262187532289 | asfimalik3      |\n",
      "| 770163251208478720 | Nderagakura4    |\n",
      "| 2155159213         | Wolfnv22        |\n",
      "| 778164143228588032 | anpcomba0       |\n",
      "| 778163712247132160 | JorgeJr53834069 |\n",
      "| 778163887690711040 | darcybelingher1 |\n",
      "| 3008506827         | james_kellyuk   |\n",
      "| 769779691116957697 | yihad_mansour   |\n",
      "| 778163243323953152 | MwangiMtetezi   |\n",
      "+--------------------+-----------------+\n"
     ]
    }
   ],
   "source": [
    "# print 20 firends and 20 followers data\n",
    "#\n",
    "cursor = db_clinton_ff[MANGODB_CLINTON_FF_COLL].find({\"type\": \"friends\"})\n",
    "print (\"\\n20 friends of Hilary Clinton\\n\")\n",
    "draw_pretty_table(cursor[0]['lst'][:20])\n",
    "\n",
    "cursor = db_clinton_ff[MANGODB_CLINTON_FF_COLL].find({\"type\": \"followers\"})\n",
    "print (\"\\n20 followers of Hilary Clinton\\n\")\n",
    "draw_pretty_table(cursor[0]['lst'][:20])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compute the mutual friends within the two groups, i.e., the users who are in both friend list and follower list, plot their ID numbers and screen names in a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{4736170399}\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "cursor = db_clinton_ff[MANGODB_CLINTON_FF_COLL].find({\"type\": \"friends\"})\n",
    "friends = cursor[0]['lst']\n",
    "cursor = db_clinton_ff[MANGODB_CLINTON_FF_COLL].find({\"type\": \"followers\"})\n",
    "followers = cursor[0]['lst']\n",
    "\n",
    "common_friends = set(friends).intersection(followers)\n",
    "\n",
    "print (common_friends)\n",
    "\n",
    "print (\"\\nMutual Friends\\n\")\n",
    "draw_pretty_table(common_friends)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*------------------------\n",
    "\n",
    "# Problem 4: Business question \n",
    "\n",
    "Run some additional experiments with your data to gain familiarity with the twitter data and twitter API.\n",
    "\n",
    "* Come up with a business question that Twitter data could help answer.\n",
    "* Decribe the business case.\n",
    "* How could Twitter data help a company decide how to spend its resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*-----------------\n",
    "# Done\n",
    "\n",
    "All set! \n",
    "\n",
    "** What do you need to submit?**\n",
    "\n",
    "* **Notebook File**: Save this IPython notebook, and find the notebook file in your folder (for example, \"filename.ipynb\"). This is the file you need to submit. Please make sure all the plotted tables and figures are in the notebook. If you used \"ipython notebook --pylab=inline\" to open the notebook, all the figures and tables should have shown up in the notebook.\n",
    "\n",
    "\n",
    "* **PPT Slides**: please prepare PPT slides (for 10 minutes' talk) to present about the case study . We will ask two teams which are randomly selected to present their case studies in class for this case study. \n",
    "\n",
    "* ** Report**: please prepare a report (less than 10 pages) to report what you found in the data.\n",
    "    * What data you collected? \n",
    "    * Why this topic is interesting or important to you? (Motivations)\n",
    "    * How did you analyse the data?\n",
    "    * What did you find in the data? \n",
    " \n",
    "     (please include figures or tables in the report, but no source code)\n",
    "\n",
    "Please compress all the files in a zipped file.\n",
    "\n",
    "\n",
    "** How to submit: **\n",
    "\n",
    "        Please submit through email to Prof. Paffenroth (rcpaffenroth@wpi.edu) *and* the TA Wen Liu (wliu3@wpi.edu).\n",
    "        \n",
    "** Note: Each team just needs to submits one submission **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grading Criteria:\n",
    "\n",
    "** Totoal Points: 120 **\n",
    "\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "** Notebook:  **\n",
    "    Points: 80\n",
    "\n",
    "\n",
    "    -----------------------------------\n",
    "    Qestion 1:\n",
    "    Points: 20\n",
    "    -----------------------------------\n",
    "    \n",
    "    (1) Select a topic that you are interested in.\n",
    "    Points: 6 \n",
    "    \n",
    "    (2) Use Twitter Streaming API to sample a collection of tweets about this topic in real time. (It would be recommended that the number of tweets should be larger than 200, but smaller than 1 million. Please check whether the total number of tweets collected is larger than 200?\n",
    "    Points: 10 \n",
    "    \n",
    "    \n",
    "    (3) Store the tweets you downloaded into a local file (txt file or json file)\n",
    "    Points: 4 \n",
    "    \n",
    "    \n",
    "    -----------------------------------\n",
    "    Qestion 2:\n",
    "    Points: 20\n",
    "    -----------------------------------\n",
    "    \n",
    "    1. Word Count\n",
    "\n",
    "    (1) Use the tweets you collected in Problem 1, and compute the frequencies of the words being used in these tweets.\n",
    "    Points: 4 \n",
    "\n",
    "    (2) Plot a table of the top 30 words with their counts \n",
    "    Points: 4 \n",
    "    \n",
    "    2. Find the most popular tweets in your collection of tweets\n",
    "    plot a table of the top 10 tweets that are the most popular among your collection, i.e., the tweets with the largest number of retweet counts.\n",
    "    Points: 4 \n",
    "    \n",
    "    3. Find the most popular Tweet Entities in your collection of tweets\n",
    "\n",
    "    (1) plot a table of the top 10 hashtags, \n",
    "    Points: 4 \n",
    "\n",
    "    (2) top 10 user mentions that are the most popular in your collection of tweets.\n",
    "    Points: 4 \n",
    "    \n",
    "    \n",
    "    -----------------------------------\n",
    "    Qestion 3:\n",
    "    Points: 20\n",
    "    -----------------------------------\n",
    "    \n",
    "    (1) choose a popular twitter user who has many followers, such as \"ladygaga\".\n",
    "    Points: 4 \n",
    "\n",
    "    (2) Get the list of all friends and all followers of the twitter user.\n",
    "    Points: 4 \n",
    "\n",
    "    (3) Plot 20 out of the followers, plot their ID numbers and screen names in a table.\n",
    "    Points: 4 \n",
    "\n",
    "    (4) Plot 20 out of the friends (if the user has more than 20 friends), plot their ID numbers and screen names in a table.\n",
    "    Points: 4 \n",
    "    \n",
    "    (5) Compute the mutual friends within the two groups, i.e., the users who are in both friend list and follower list, plot their ID numbers and screen names in a table\n",
    "    Points: 4 \n",
    "  \n",
    "    -----------------------------------\n",
    "    Qestion 4:  Business question\n",
    "    Points: 20\n",
    "    -----------------------------------\n",
    "        Novelty: 10\n",
    "        Interestingness: 10\n",
    "    -----------------------------------\n",
    "    Run some additional experiments with your data to gain familiarity with the twitter data ant twitter API.  Come up with a business question and describe how Twitter data can help you answer that question.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "** Report: communicate the results**\n",
    "    Points: 20\n",
    "\n",
    "(1) What data you collected?\n",
    "    Points: 5 \n",
    "\n",
    "(2) Why this topic is interesting or important to you? (Motivations)\n",
    "    Points: 5 \n",
    "\n",
    "(3) How did you analyse the data?\n",
    "    Points: 5 \n",
    "\n",
    "(4) What did you find in the data?\n",
    "(please include figures or tables in the report, but no source code)\n",
    "    Points: 5 \n",
    "\n",
    "\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "** Slides (for 10 minutes of presentation): Story-telling **\n",
    "    Points: 20\n",
    "\n",
    "\n",
    "1. Motivation about the data collection, why the topic is interesting to you.\n",
    "    Points: 5 \n",
    "\n",
    "2. Communicating Results (figure/table)\n",
    "    Points: 10 \n",
    "\n",
    "3. Story telling (How all the parts (data, analysis, result) fit together as a story?)\n",
    "    Points: 5 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
