{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study 1 : Collecting Data from Twitter\n",
    "\n",
    "Due Date: September 22, **before the beginning of class at 6:00pm**\n",
    "\n",
    "* ------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/en/thumb/9/9f/Twitter_bird_logo_2012.svg/220px-Twitter_bird_logo_2012.svg.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TEAM Members:**\n",
    "\n",
    "    Matthew Beaulieu\n",
    "    \n",
    "    Yousef Fadila\n",
    "    \n",
    "    Meng Li\n",
    "    \n",
    "    Monica Tlachac\n",
    "    \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Required Readings:** \n",
    "* Chapter 1 and Chapter 9 of the book [Mining the Social Web](http://www.learndatasci.com/wp-content/uploads/2015/08/Mining-the-Social-Web-2nd-Edition.pdf) \n",
    "* The codes for [Chapter 1](http://bit.ly/1qCtMrr) and [Chapter 9](http://bit.ly/1u7eP33)\n",
    "\n",
    "\n",
    "** NOTE **\n",
    "* Please don't forget to save the notebook frequently when working in IPython Notebook, otherwise the changes you made can be lost.\n",
    "\n",
    "*----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Sampling Twitter Data with Streaming API about a certain topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Select a topic that you are interested in, for example, \"WPI\" or \"Lady Gaga\"\n",
    "* Use Twitter Streaming API to sample a collection of tweets about this topic in real time. (It would be recommended that the number of tweets should be larger than 200, but smaller than 1 million.\n",
    "* Store the tweets you downloaded into a local file (txt file or json file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import warnings\n",
    "import json\n",
    "import numpy as np\n",
    "import wikiwords\n",
    "from tweepy import Stream\n",
    "from tweepy.streaming import StreamListener\n",
    "import pymongo\n",
    "import tweepy\n",
    "import re\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "warnings.simplefilter(action = \"ignore\", category = FutureWarning)\n",
    "%matplotlib inline\n",
    "#---------------------------------------------\n",
    "# Define a Function to Login Twitter API\n",
    "#\n",
    "# XXX  - DON'T COMMIT TRUE CREDINTIALS TO GITHUB\n",
    "CONSUMER_KEY = 'k01qrrsDSOHdjUObbt1pWjhld'\n",
    "CONSUMER_SECRET ='FTBSa4UU5Nxaw00hNPJQvoAf60HinJM87GfQpuFM0YsVKDdoJD'\n",
    "OAUTH_TOKEN = '4229853605-mSgVKfVSZ9BSN7GbPgvUIPOT1Xl6F3nA2ynKMvy'\n",
    "OAUTH_TOKEN_SECRET = 'jyHtNVKGmqNw4HyBLMYG5i9BT3junKGVFnY6CE2tjJRFW'\n",
    "\n",
    "# another set of auth to use when limit is hit.\n",
    "#CONSUMER_KEY = '7n45AnattFU5sb3MpbiwIoNYF'\n",
    "#CONSUMER_SECRET ='VtnEmlR99dG3hQ8FP8xb1TnomTAjSGkQYDJVhGa28IDPDEA2Cf'\n",
    "#OAUTH_TOKEN = '2497861306-W7d3EXegd4AY6jYt9ZaEz5rq5ZtguAAtp6KbseS'\n",
    "#OAUTH_TOKEN_SECRET = 'uv71S6pJwPibOFLA8WetoxWRb0nfqcQPK8f3ts30nEfQT'\n",
    "\n",
    "# mango db auth.\n",
    "MANGODB_SERVER = 'ds033046.mlab.com'\n",
    "MANGODB_PORT = 33046\n",
    "MANGODB_USER = 'ds501u'\n",
    "MANGODB_PASS = 'ds501p'\n",
    "MANGODB_NAME = 'ds501case1'\n",
    "MANGODB_COLLECTION = 'tweets'\n",
    "GEOBOX_USA = [-125,25.1,-60.5,49.1]\n",
    "us_states = [\"WA\" , \"DE\" , \"WI\" , \"WV\" , \"HI\" , \"FL\" , \"WY\" , \"NH\" , \"NJ\" , \"NM\" , \"TX\" , \"LA\" , \"NC\" , \"ND\" , \"NE\" , \"TN\" , \"NY\" , \"PA\" , \"CA\" , \"NV\" , \"VA\" , \"CO\" , \"AK\" , \"AL\" , \"AR\" , \"VT\" , \"IL\" , \"GA\" , \"IN\" , \"IA\" , \"OK\" , \"AZ\" , \"ID\" , \"CT\" , \"ME\" , \"MD\" , \"MA\" , \"OH\" , \"UT\" , \"MO\" , \"MN\" , \"MI\" , \"RI\" , \"KS\" , \"MT\" , \"MS\" , \"SC\" , \"KY\" , \"OR\" , \"SD\" ] \n",
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(OAUTH_TOKEN, OAUTH_TOKEN_SECRET)\n",
    "\n",
    "db_client = pymongo.MongoClient(MANGODB_SERVER, MANGODB_PORT)\n",
    "db = db_client[MANGODB_NAME]\n",
    "db.authenticate(MANGODB_USER, MANGODB_PASS)\n",
    "tweets_Collection = db[MANGODB_COLLECTION]\n",
    "#----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StreamListener' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9198cea34963>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mMyListener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStreamListener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mMANGODB_COLLECTION\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'StreamListener' is not defined"
     ]
    }
   ],
   "source": [
    "class MyListener(StreamListener):\n",
    "    def __init__(self, max_count = 100):\n",
    "        self.count = 0\n",
    "        self.max_count = max_count   \n",
    "        self.collection = db[MANGODB_COLLECTION]\n",
    "\n",
    "    def on_data(self, data):\n",
    "        try:\n",
    "            if self.count >= self.max_count:\n",
    "                return False\n",
    "            # the question require output to file. so output to file and save in mangoDB\n",
    "            with open('data/hillary.json', 'a') as f:\n",
    "                f.write(data)\n",
    "            self.count = self.count + 1\n",
    "            datajson = json.loads(data)\n",
    "            self.collection.insert_one(datajson)\n",
    "            return True\n",
    "        except BaseException as e:\n",
    "            print(e)\n",
    "        return True\n",
    " \n",
    "    def on_error(self, status):\n",
    "        print(status)\n",
    "        return True\n",
    "    \n",
    "api = tweepy.API(auth)\n",
    "limit = 20000\n",
    "twitter_stream = Stream(auth, MyListener(limit))\n",
    "twitter_stream.filter(track=['@HillaryClinton'], languages=[\"en\"], locations=GEOBOX_USA)\n",
    "print(\"streaming done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report some statistics about the tweets you collected \n",
    "\n",
    "* The topic of interest: Hillary Clinton                   \n",
    "\n",
    "\n",
    "* The total number of tweets collected:  17000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Analyzing Tweets and Tweet Entities with Frequency Analysis\n",
    "\n",
    "**1. Word Count:** \n",
    "* Use the tweets you collected in Problem 1, and compute the frequencies of the words being used in these tweets. \n",
    "* Plot a table of the top 30 words with their counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting Text from Tweets** \n",
    "\n",
    "* Get the text column of the tweet df\n",
    "* make it lower case\n",
    "* remove http links and non alphanum characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "################# RE WRITE THIS - DF is not defined in this context. define it or loop over database/file. your coice\n",
    "lst = []\n",
    "with open('data/hillary.json', 'r') as f:\n",
    "    for line in f:\n",
    "        tweet = json.loads(line)\n",
    "        lst.append(tweet)\n",
    "\n",
    "df = pd.DataFrame(lst)    \n",
    "text = df.text.str.lower()\n",
    "\n",
    "for i,t in enumerate(text):\n",
    "    t = re.sub(r\"(?:\\@|https?\\://)\\S+\", \"\", t)\n",
    "    new = ''.join(e for e in t if (e.isalnum() or e==' '))\n",
    "    text[i] = new\n",
    "text = text.str.split(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a dictionary with each unique word as the key, and the number of times it appears as the value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_dict = {}\n",
    "for r in range(text.shape[0]):\n",
    "    lis = text.values[r]\n",
    "    for word in lis:\n",
    "        if word in word_dict.keys():\n",
    "            word_dict[word] +=1\n",
    "        else:\n",
    "            word_dict[word] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the key, value pairs to a dictionary (after removing rt, lingering https, and hillaryclinton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vals</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6054</th>\n",
       "      <td>4282</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2269</th>\n",
       "      <td>4097</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9750</th>\n",
       "      <td>2886</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5175</th>\n",
       "      <td>2681</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2139</th>\n",
       "      <td>2525</td>\n",
       "      <td>you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2805</th>\n",
       "      <td>2281</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8748</th>\n",
       "      <td>2036</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>1883</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3973</th>\n",
       "      <td>1666</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1691</th>\n",
       "      <td>1575</td>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9965</th>\n",
       "      <td>1381</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9586</th>\n",
       "      <td>1295</td>\n",
       "      <td>her</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2699</th>\n",
       "      <td>1255</td>\n",
       "      <td>that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>1190</td>\n",
       "      <td>this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2510</th>\n",
       "      <td>1156</td>\n",
       "      <td>your</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4911</th>\n",
       "      <td>1103</td>\n",
       "      <td>she</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6993</th>\n",
       "      <td>1072</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>1061</td>\n",
       "      <td>are</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5895</th>\n",
       "      <td>993</td>\n",
       "      <td>trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10725</th>\n",
       "      <td>968</td>\n",
       "      <td>amp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7447</th>\n",
       "      <td>915</td>\n",
       "      <td>hillary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4568</th>\n",
       "      <td>898</td>\n",
       "      <td>has</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10666</th>\n",
       "      <td>898</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10954</th>\n",
       "      <td>855</td>\n",
       "      <td>not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5058</th>\n",
       "      <td>797</td>\n",
       "      <td>we</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4855</th>\n",
       "      <td>787</td>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4165</th>\n",
       "      <td>751</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10062</th>\n",
       "      <td>717</td>\n",
       "      <td>with</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4046</th>\n",
       "      <td>684</td>\n",
       "      <td>what</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7737</th>\n",
       "      <td>654</td>\n",
       "      <td>about</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       vals    words\n",
       "6054   4282       to\n",
       "2269   4097      the\n",
       "9750   2886       is\n",
       "5175   2681        a\n",
       "2139   2525      you\n",
       "2805   2281       of\n",
       "8748   2036      for\n",
       "361    1883       in\n",
       "3973   1666      and\n",
       "1691   1575       on\n",
       "9965   1381        i\n",
       "9586   1295      her\n",
       "2699   1255     that\n",
       "829    1190     this\n",
       "2510   1156     your\n",
       "4911   1103      she\n",
       "6993   1072       it\n",
       "86     1061      are\n",
       "5895    993    trump\n",
       "10725   968      amp\n",
       "7447    915  hillary\n",
       "4568    898      has\n",
       "10666   898      all\n",
       "10954   855      not\n",
       "5058    797       we\n",
       "4855    787       be\n",
       "4165    751       no\n",
       "10062   717     with\n",
       "4046    684     what\n",
       "7737    654    about"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals = []\n",
    "remove_list = ['', ' ', 'rt', 'http','https','hillaryclinton']\n",
    "keys = [ e for e in word_dict.keys() if e not in remove_list]\n",
    "for key in keys:\n",
    "    vals.append(word_dict.get(key))\n",
    "    \n",
    "tweet_df = pd.DataFrame({'words':keys, 'vals':vals})\n",
    "tweet_df = tweet_df.sort_values('vals', ascending=False)\n",
    "tweet_df[0:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon first anlysis, the 30 most used words in the tweets we pulled are pretty common, with special cases such as \"hillary\", and \"trump\".  \n",
    "\n",
    "The next strategy was to normalize each tweet for how popular it is in the English language, to find a more interesting top word count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vals</th>\n",
       "      <th>words</th>\n",
       "      <th>freq</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10725</th>\n",
       "      <td>968</td>\n",
       "      <td>amp</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>2.649444e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5457</th>\n",
       "      <td>391</td>\n",
       "      <td>hypocrisy</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2.041077e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5895</th>\n",
       "      <td>993</td>\n",
       "      <td>trump</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1.673466e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7447</th>\n",
       "      <td>915</td>\n",
       "      <td>hillary</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1.660476e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9119</th>\n",
       "      <td>236</td>\n",
       "      <td>unfit</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.062605e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4707</th>\n",
       "      <td>104</td>\n",
       "      <td>yells</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.025306e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9265</th>\n",
       "      <td>290</td>\n",
       "      <td>stunning</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>8.027490e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5694</th>\n",
       "      <td>97</td>\n",
       "      <td>yrs</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>7.345456e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7440</th>\n",
       "      <td>115</td>\n",
       "      <td>bodyguards</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>7.057417e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>82</td>\n",
       "      <td>benghazi</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>6.487133e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9505</th>\n",
       "      <td>207</td>\n",
       "      <td>doesnt</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.278809e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>268</td>\n",
       "      <td>cant</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>6.045840e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2228</th>\n",
       "      <td>94</td>\n",
       "      <td>didnt</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>5.126433e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11630</th>\n",
       "      <td>86</td>\n",
       "      <td>trumps</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>4.904659e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9479</th>\n",
       "      <td>94</td>\n",
       "      <td>wont</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>4.811936e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5508</th>\n",
       "      <td>91</td>\n",
       "      <td>poorest</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>4.258990e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2065</th>\n",
       "      <td>42</td>\n",
       "      <td>dnc</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>4.021426e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5645</th>\n",
       "      <td>412</td>\n",
       "      <td>lets</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>3.826785e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3811</th>\n",
       "      <td>75</td>\n",
       "      <td>whats</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>3.786318e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5550</th>\n",
       "      <td>104</td>\n",
       "      <td>realises</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>3.763119e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5335</th>\n",
       "      <td>142</td>\n",
       "      <td>liar</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>3.719576e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>73</td>\n",
       "      <td>blackmail</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>3.535690e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>36</td>\n",
       "      <td>tweet</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.457496e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6873</th>\n",
       "      <td>389</td>\n",
       "      <td>dont</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>3.437822e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7531</th>\n",
       "      <td>148</td>\n",
       "      <td>pneumonia</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>3.434423e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7425</th>\n",
       "      <td>55</td>\n",
       "      <td>footing</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>3.303236e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7694</th>\n",
       "      <td>35</td>\n",
       "      <td>audiobook</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.113467e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1893</th>\n",
       "      <td>180</td>\n",
       "      <td>thats</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>3.059080e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>63</td>\n",
       "      <td>isnt</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2.780705e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8562</th>\n",
       "      <td>128</td>\n",
       "      <td>donors</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>2.747749e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       vals       words      freq         ratio\n",
       "10725   968         amp  0.000004  2.649444e+08\n",
       "5457    391   hypocrisy  0.000002  2.041077e+08\n",
       "5895    993       trump  0.000006  1.673466e+08\n",
       "7447    915     hillary  0.000006  1.660476e+08\n",
       "9119    236       unfit  0.000002  1.062605e+08\n",
       "4707    104       yells  0.000001  1.025306e+08\n",
       "9265    290    stunning  0.000004  8.027490e+07\n",
       "5694     97         yrs  0.000001  7.345456e+07\n",
       "7440    115  bodyguards  0.000002  7.057417e+07\n",
       "1444     82    benghazi  0.000001  6.487133e+07\n",
       "9505    207      doesnt  0.000003  6.278809e+07\n",
       "850     268        cant  0.000004  6.045840e+07\n",
       "2228     94       didnt  0.000002  5.126433e+07\n",
       "11630    86      trumps  0.000002  4.904659e+07\n",
       "9479     94        wont  0.000002  4.811936e+07\n",
       "5508     91     poorest  0.000002  4.258990e+07\n",
       "2065     42         dnc  0.000001  4.021426e+07\n",
       "5645    412        lets  0.000011  3.826785e+07\n",
       "3811     75       whats  0.000002  3.786318e+07\n",
       "5550    104    realises  0.000003  3.763119e+07\n",
       "5335    142        liar  0.000004  3.719576e+07\n",
       "1616     73   blackmail  0.000002  3.535690e+07\n",
       "1437     36       tweet  0.000001  3.457496e+07\n",
       "6873    389        dont  0.000011  3.437822e+07\n",
       "7531    148   pneumonia  0.000004  3.434423e+07\n",
       "7425     55     footing  0.000002  3.303236e+07\n",
       "7694     35   audiobook  0.000001  3.113467e+07\n",
       "1893    180       thats  0.000006  3.059080e+07\n",
       "417      63        isnt  0.000002  2.780705e+07\n",
       "8562    128      donors  0.000005  2.747749e+07"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wikiwords is a cool library that tells how often a word appears in wikipedia articles\n",
    "# and works to normalize for word popularity\n",
    "tweet_df['freq'] = tweet_df['words'].apply(wikiwords.freq)\n",
    "tweet_df = tweet_df[tweet_df['freq'] > 1.0e-6]\n",
    "tweet_df['ratio'] = tweet_df['vals'] / tweet_df['freq']\n",
    "tweet_df.sort_values('ratio', ascending=False)[0:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This list is much more interesting, with words like Benghazi, stunning, hypocrisy, and unfit, seeming like more specific to the subject being discussed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Find the most popular tweets in your collection of tweets**\n",
    "\n",
    "Please plot a table of the top 10 tweets that are the most popular among your collection, i.e., the tweets with the largest number of retweet counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the tweets are already loaded into a Pandas DataFrame, this part should be pretty straightforward..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@BoyGeorge @HillaryClinton Don't be sorry for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9659</th>\n",
       "      <td>0</td>\n",
       "      <td>@HillaryClinton get off my feed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9660</th>\n",
       "      <td>0</td>\n",
       "      <td>RT @Delo_Taylor: After 8 yrs of neglect all @P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9661</th>\n",
       "      <td>0</td>\n",
       "      <td>Please retweet twitter blocking comments https...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9662</th>\n",
       "      <td>0</td>\n",
       "      <td>@ClintonFdn @HillaryClinton \\n\\nhttps://t.co/y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9663</th>\n",
       "      <td>0</td>\n",
       "      <td>RT @Bikers4Trump: After the 3 Terrorist Attack...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9664</th>\n",
       "      <td>0</td>\n",
       "      <td>@BarbaraAResEsq @Cuckerella let's not forget @...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9665</th>\n",
       "      <td>0</td>\n",
       "      <td>RT @FoxNews: .@JudgeJeanine to @HillaryClinton...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9666</th>\n",
       "      <td>0</td>\n",
       "      <td>RT @Someweirdid: @BrianAbelTV @HillaryClinton ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9667</th>\n",
       "      <td>0</td>\n",
       "      <td>@HillaryClinton At some point you MUST address...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      retweet_count                                               text\n",
       "0                 0  @BoyGeorge @HillaryClinton Don't be sorry for ...\n",
       "9659              0                    @HillaryClinton get off my feed\n",
       "9660              0  RT @Delo_Taylor: After 8 yrs of neglect all @P...\n",
       "9661              0  Please retweet twitter blocking comments https...\n",
       "9662              0  @ClintonFdn @HillaryClinton \\n\\nhttps://t.co/y...\n",
       "9663              0  RT @Bikers4Trump: After the 3 Terrorist Attack...\n",
       "9664              0  @BarbaraAResEsq @Cuckerella let's not forget @...\n",
       "9665              0  RT @FoxNews: .@JudgeJeanine to @HillaryClinton...\n",
       "9666              0  RT @Someweirdid: @BrianAbelTV @HillaryClinton ...\n",
       "9667              0  @HillaryClinton At some point you MUST address..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values('retweet_count', ascending='False')[['retweet_count', 'text']][0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, these tweets were pulled from the twitter streaming API, meaning we saved the tweets as they appeared, and before they were retweeted or favorited by any of the user base.\n",
    "\n",
    "To fix this, we pulled 1/10 of them again from the REST API (not the whole set due to rate limits), saved it to a JSON, loaded it to a df, and ran the command again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lst = []\n",
    "with open('data/update_hillary.json', 'r') as f:\n",
    "    for line in f:\n",
    "        tweet = json.loads(line)\n",
    "        lst.append(tweet)\n",
    "new_df = pd.DataFrame(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>{'description': 'It's time to DRAIN THE SWAMP!...</td>\n",
       "      <td>17540</td>\n",
       "      <td>RT @YoungDems4Trump: Show this to those who do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>{'description': '', 'name': 'GoWithItJam', 'pr...</td>\n",
       "      <td>6426</td>\n",
       "      <td>RT @bfraser747: ðŸ’¥ðŸ’¥ BREAKING NEWS  ðŸ’¥ðŸ’¥\\n\\nNobody...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>{'description': '@HeiressLegitima @PossessGods...</td>\n",
       "      <td>2149</td>\n",
       "      <td>RT @SenGillibrand: Love this.\\n\\n\"@HillaryClin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>{'name': 'CB', 'profile_sidebar_fill_color': '...</td>\n",
       "      <td>2076</td>\n",
       "      <td>RT @Harlan: Whoa, this is a BRUTAL take on @Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>{'name': 'Vahe', 'profile_sidebar_fill_color':...</td>\n",
       "      <td>1804</td>\n",
       "      <td>RT @RealBenCarson: @HillaryClinton hiding her ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>{'description': 'The thought of a Hillary pres...</td>\n",
       "      <td>1758</td>\n",
       "      <td>RT @DrJillStein: Obama admin including @Hillar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>{'description': 'Patriot- Trump2016-Independen...</td>\n",
       "      <td>1587</td>\n",
       "      <td>RT @FoxNews: Fox News Poll: @realDonaldTrump l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>{'description': 'Beirut Vet. Former United Sta...</td>\n",
       "      <td>1586</td>\n",
       "      <td>RT @FoxNews: Fox News Poll: @realDonaldTrump l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>{'description': '', 'name': 'Life Lessons', 'p...</td>\n",
       "      <td>1392</td>\n",
       "      <td>RT @Jorge_Silva: Celebrating #HispanicHeritage...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>{'description': 'Deplorable Wife, Mom, Conserv...</td>\n",
       "      <td>1385</td>\n",
       "      <td>RT @ImWithYou010: @hillaryclinton talking abou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   user  retweet_count  \\\n",
       "605   {'description': 'It's time to DRAIN THE SWAMP!...          17540   \n",
       "837   {'description': '', 'name': 'GoWithItJam', 'pr...           6426   \n",
       "1106  {'description': '@HeiressLegitima @PossessGods...           2149   \n",
       "1100  {'name': 'CB', 'profile_sidebar_fill_color': '...           2076   \n",
       "615   {'name': 'Vahe', 'profile_sidebar_fill_color':...           1804   \n",
       "402   {'description': 'The thought of a Hillary pres...           1758   \n",
       "969   {'description': 'Patriot- Trump2016-Independen...           1587   \n",
       "666   {'description': 'Beirut Vet. Former United Sta...           1586   \n",
       "1131  {'description': '', 'name': 'Life Lessons', 'p...           1392   \n",
       "465   {'description': 'Deplorable Wife, Mom, Conserv...           1385   \n",
       "\n",
       "                                                   text  \n",
       "605   RT @YoungDems4Trump: Show this to those who do...  \n",
       "837   RT @bfraser747: ðŸ’¥ðŸ’¥ BREAKING NEWS  ðŸ’¥ðŸ’¥\\n\\nNobody...  \n",
       "1106  RT @SenGillibrand: Love this.\\n\\n\"@HillaryClin...  \n",
       "1100  RT @Harlan: Whoa, this is a BRUTAL take on @Hi...  \n",
       "615   RT @RealBenCarson: @HillaryClinton hiding her ...  \n",
       "402   RT @DrJillStein: Obama admin including @Hillar...  \n",
       "969   RT @FoxNews: Fox News Poll: @realDonaldTrump l...  \n",
       "666   RT @FoxNews: Fox News Poll: @realDonaldTrump l...  \n",
       "1131  RT @Jorge_Silva: Celebrating #HispanicHeritage...  \n",
       "465   RT @ImWithYou010: @hillaryclinton talking abou...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop duplicates is used because on retweeted tweets, twitter stores\n",
    "# the retweet count from the source tweet, for all of them, so there were several repeats\n",
    "new_df.sort_values('retweet_count', ascending=False)[['user', 'retweet_count', 'text']][0:100].drop_duplicates('retweet_count')[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pulled ~1000 of our tweets from the rest API after they'd existed for a period of time, and could be retweeted. These are the 10 most popular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Find the most popular Tweet Entities in your collection of tweets**\n",
    "\n",
    "Please plot a table of the top 10 hashtags, top 10 user mentions that are the most popular in your collection of tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "    \n",
    "def print_top_entities(label, entities, max_to_show):\n",
    "    pt = PrettyTable(field_names=[label, 'Count'])\n",
    "    c = Counter(entities)\n",
    "    [ pt.add_row(kv) for kv in c.most_common()[:max_to_show] ]\n",
    "    pt.align[label], pt.align['Count'] = 'l', 'r' # Set column alignment\n",
    "    print(pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------+\n",
      "| screen name     | Count |\n",
      "+-----------------+-------+\n",
      "| HillaryClinton  | 15421 |\n",
      "| realDonaldTrump |  2718 |\n",
      "| FoxNews         |  1532 |\n",
      "| POTUS           |   503 |\n",
      "| CNN             |   481 |\n",
      "| politico        |   283 |\n",
      "| timkaine        |   263 |\n",
      "| FLOTUS          |   245 |\n",
      "| MSNBC           |   244 |\n",
      "| USAneedsTRUMP   |   235 |\n",
      "+-----------------+-------+\n",
      "+-----------------------+-------+\n",
      "| hashtag               | Count |\n",
      "+-----------------------+-------+\n",
      "| MAGA                  |   385 |\n",
      "| ImWithHer             |   351 |\n",
      "| SpecialReport         |   209 |\n",
      "| NeverHillary          |   178 |\n",
      "| DNCleak               |   177 |\n",
      "| HispanicHeritageMonth |   163 |\n",
      "| tcot                  |   156 |\n",
      "| Trump                 |   149 |\n",
      "| TrumpPence16          |   125 |\n",
      "| HillaryHealth         |   102 |\n",
      "+-----------------------+-------+\n"
     ]
    }
   ],
   "source": [
    "cursor = tweets_Collection.find()\n",
    "screen_names = [ user_mention['screen_name'] \n",
    "                 for tweet in cursor\n",
    "                     for user_mention in tweet['entities']['user_mentions'] ]\n",
    "\n",
    "print_top_entities('screen name', screen_names, 10)\n",
    "\n",
    "cursor = tweets_Collection.find()\n",
    "hashtags = [ hashtag['text'] \n",
    "             for tweet in cursor\n",
    "                 for hashtag in tweet['entities']['hashtags'] ]\n",
    "\n",
    "print_top_entities('hashtag', hashtags, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ------------------------\n",
    "\n",
    "# Problem 3: Getting \"All\" friends and \"All\" followers of a popular user in twitter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* choose a popular twitter user who has many followers, such as \"ladygaga\".\n",
    "* Get the list of all friends and all followers of the twitter user.\n",
    "* Plot 20 out of the followers, plot their ID numbers and screen names in a table.\n",
    "* Plot 20 out of the friends (if the user has more than 20 friends), plot their ID numbers and screen names in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#definitios and config values\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "MANGODB_SERVER = 'ds035816.mlab.com'\n",
    "MANGODB_PORT = 35816\n",
    "MANGODB_CLINTON_FF_DB_NAME = \"clintonff\"\n",
    "MANGODB_CLINTON_FF_COLL = \"collection\"\n",
    "db_clinton_ff_client = pymongo.MongoClient(MANGODB_SERVER, MANGODB_PORT)\n",
    "db_clinton_ff = db_clinton_ff_client[MANGODB_CLINTON_FF_DB_NAME]\n",
    "db_clinton_ff.authenticate(MANGODB_USER, MANGODB_PASS)  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# fetch all followers \n",
    "import time\n",
    "data_followers = {}\n",
    "data_followers['type'] = 'followers'\n",
    "data_followers['lst'] = []\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertOneResult at 0x12e2a9438>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fetch all friends\n",
    "#no need for iteration like fetching followers as number of friends is relatvely small\n",
    "data_friends = {}\n",
    "data_friends['type'] = 'friends'\n",
    "data_friends['lst'] = []\n",
    "\n",
    "# fetch all friends list - as this list relativly samll we won't hit the limit here.\n",
    "\n",
    "friends_ids = []     \n",
    "for itm in tweepy.Cursor(api.friends_ids, id = 'HillaryClinton').items():\n",
    "    data_friends['lst'].append(itm)\n",
    "\n",
    "# save the friend's list in mangoDB    \n",
    "friends_json = json.loads(json.dumps(data_friends))  \n",
    "db_clinton_ff[MANGODB_CLINTON_FF_COLL].insert_one(friends_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Given a set of user ids, this function calls get_screen_names and plots a table of the first (max_ids) ID's and screen names.\n",
    "def draw_pretty_table(ids):\n",
    "    users = api.lookup_users(user_ids=ids)\n",
    "    pretty_table = PrettyTable(['ID','Screen Name'])\n",
    "    [pretty_table.add_row ([row.id,row.screen_name]) for row in users]\n",
    "    pretty_table.align = 'l'\n",
    "    print(pretty_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "20 friends of Hilary Clinton\n",
      "\n",
      "+--------------------+----------------+\n",
      "| ID                 | Screen Name    |\n",
      "+--------------------+----------------+\n",
      "| 571202103          | Medium         |\n",
      "| 21337440           | ChildDefender  |\n",
      "| 23449384           | amberdiscko    |\n",
      "| 128790234          | Samynemir      |\n",
      "| 1656913327         | sarajacobs89   |\n",
      "| 325886383          | SammyKoppelman |\n",
      "| 802430450          | Natasha_S_Law  |\n",
      "| 729761993461248000 | ktvibbs        |\n",
      "| 115740215          | SarahAudelo    |\n",
      "| 34782406           | Lincoln_Ross   |\n",
      "| 3044781131         | HillaryforAR   |\n",
      "| 113298560          | GunaRockYa     |\n",
      "| 15972271           | CdotDukes      |\n",
      "| 582037089          | MiguelAyala312 |\n",
      "| 734768872625188864 | AndrewBatesNC  |\n",
      "| 41021335           | TroyClair      |\n",
      "| 4736170399         | BrianZuzenak   |\n",
      "| 150885854          | SarahPeckVA    |\n",
      "| 231673             | yianni         |\n",
      "| 125083946          | GillDrummond   |\n",
      "+--------------------+----------------+\n",
      "\n",
      "20 followers of Hilary Clinton\n",
      "\n",
      "+--------------------+-----------------+\n",
      "| ID                 | Screen Name     |\n",
      "+--------------------+-----------------+\n",
      "| 721621392          | zaidiih         |\n",
      "| 778554396334497792 | MarshallBarton7 |\n",
      "| 778555270117064704 | PuppyJanette    |\n",
      "| 778554532129304576 | west6836        |\n",
      "| 778554806809964544 | moses_stetson   |\n",
      "| 778555351801094144 | jackywlc        |\n",
      "| 778555242233430016 | Flexing_Camelli |\n",
      "| 778554596218200064 | NyambanzaGlandy |\n",
      "| 778555070745116672 | andrewanita690  |\n",
      "| 778553288052449281 | dzm52           |\n",
      "| 778554264616636416 | Hakimchagma1    |\n",
      "| 778553278401576960 | esperancekadang |\n",
      "| 2787789404         | WangeciThuita   |\n",
      "| 778543843020906496 | Azzukalam5      |\n",
      "| 778555371833044992 | martinez_herves |\n",
      "| 778553871299907584 | Ahm2016Omar     |\n",
      "| 341658118          | Ah700           |\n",
      "| 778552518620119041 | JessicaQuintel  |\n",
      "| 778554593131331584 | IdnunnOa2g6wfQJ |\n",
      "| 778248548840251392 | melija28        |\n",
      "+--------------------+-----------------+\n"
     ]
    }
   ],
   "source": [
    "# print 20 firends and 20 followers data\n",
    "#\n",
    "cursor = db_clinton_ff[MANGODB_CLINTON_FF_COLL].find({\"type\": \"friends\"})\n",
    "print (\"\\n20 friends of Hilary Clinton\\n\")\n",
    "draw_pretty_table(cursor[0]['lst'][:20])\n",
    "\n",
    "cursor = db_clinton_ff[MANGODB_CLINTON_FF_COLL].find({\"type\": \"followers\"})\n",
    "print (\"\\n20 followers of Hilary Clinton\\n\")\n",
    "draw_pretty_table(cursor[0]['lst'][:20])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compute the mutual friends within the two groups, i.e., the users who are in both friend list and follower list, plot their ID numbers and screen names in a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This list is not a complete one as it requires about 30 hours to fetch all followers of \n",
      " Clinto due to twitter rate limit\n",
      " we fetched about 4M out of 8M followers\n",
      "\n",
      "Mutual Friends table\n",
      "+--------------------+-----------------+\n",
      "| ID                 | Screen Name     |\n",
      "+--------------------+-----------------+\n",
      "| 3068729259         | HillaryforND    |\n",
      "| 3065862285         | HillaryforNJ    |\n",
      "| 172858784          | timkaine        |\n",
      "| 3064597541         | HillaryforMO    |\n",
      "| 3044781131         | HillaryforAR    |\n",
      "| 3073392597         | HillaryforSD    |\n",
      "| 3078554829         | HillaryforTX    |\n",
      "| 3057577828         | HillaryforIN    |\n",
      "| 3073477156         | HillaryforTN    |\n",
      "| 99545933           | mouto77         |\n",
      "| 3086798481         | HillaryforWV    |\n",
      "| 3044746419         | HillaryforCA    |\n",
      "| 3047899581         | HillaryforCT    |\n",
      "| 758346398156881920 | HRCforRI        |\n",
      "| 3060191026         | HillaryforMA    |\n",
      "| 3057542915         | HillaryforKY    |\n",
      "| 3048168670         | HillaryforDE    |\n",
      "| 3060143603         | HillaryforMD    |\n",
      "| 139939973          | jpbmayor        |\n",
      "| 4884965834         | HillaryforUT    |\n",
      "| 755024857373474816 | Hillary_esp     |\n",
      "| 3044710461         | HillaryforAZ    |\n",
      "| 3031619171         | HillaryforAL    |\n",
      "| 3058863113         | HillaryforLA    |\n",
      "| 3068825260         | HillaryforOK    |\n",
      "| 3068783345         | HillaryforOR    |\n",
      "| 3052911538         | HillaryForGA    |\n",
      "| 3065982773         | HillaryforNM    |\n",
      "| 1287341107         | DaveTencza      |\n",
      "| 31393043           | NHkaren         |\n",
      "| 83668232           | JesseFFerguson  |\n",
      "| 23449384           | amberdiscko     |\n",
      "| 8370082            | DemConvention   |\n",
      "| 3061981559         | HillaryforMI    |\n",
      "| 747148719225610240 | gsanchofl       |\n",
      "| 746719903210737664 | VallveRendi     |\n",
      "| 746432638701834240 | Scherlie_       |\n",
      "| 130288787          | DevanQuinn      |\n",
      "| 43703569           | peggygilmour    |\n",
      "| 59238835           | GarthCorriveau  |\n",
      "| 1033943323         | sueford06       |\n",
      "| 1931494634         | ezradf          |\n",
      "| 25238413           | MollyMurph      |\n",
      "| 3081659314         | HillaryforVA    |\n",
      "| 3065967867         | HillaryforNC    |\n",
      "| 3068811118         | HillaryforOH    |\n",
      "| 41021335           | TroyClair       |\n",
      "| 12434632           | wssrstrm        |\n",
      "| 3088855679         | HillaryforWI    |\n",
      "| 15972271           | CdotDukes       |\n",
      "| 734768872625188864 | AndrewBatesNC   |\n",
      "| 734502816111267840 | sarah4dems      |\n",
      "| 26919151           | AmyDugan        |\n",
      "| 734080232580382721 | austinreagan16  |\n",
      "| 729761993461248000 | ktvibbs         |\n",
      "| 18220818           | Donna_West      |\n",
      "| 1923862850         | lisachangadveja |\n",
      "| 24289404           | JaimieAlexander |\n",
      "+--------------------+-----------------+\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "cursor = db_clinton_ff[MANGODB_CLINTON_FF_COLL].find({\"type\": \"friends\"})\n",
    "friends = cursor[0]['lst']\n",
    "cursor = db_clinton_ff[MANGODB_CLINTON_FF_COLL].find({\"type\": \"followers\"})\n",
    "\n",
    "# we have 1 list of friends (~800 members) and over 500 list of followers; each of 5000 members,\n",
    "#iterate over the followers and build the intersaction list\n",
    "common_friends = []\n",
    "total = 0\n",
    "for follower in cursor:\n",
    "    common_friends.extend(set(friends).intersection(follower['lst']))\n",
    "    total += len(follower['lst'])\n",
    "    \n",
    "#print ('Clinton has {} followers; {} following ; {} mutal friends'.format(total, len(friends), len(common_friends)))\n",
    "print(\"This list is not a complete one as it requires about 30 hours to fetch all followers of \\n Clinto due to twitter rate limit\\n we fetched about 4M out of 8M followers\\n\")\n",
    "print (\"Mutual Friends table\")\n",
    "draw_pretty_table(common_friends)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*------------------------\n",
    "\n",
    "# Problem 4: Business question \n",
    "\n",
    "Run some additional experiments with your data to gain familiarity with the twitter data and twitter API.\n",
    "\n",
    "* Come up with a business question that Twitter data could help answer.\n",
    "* Decribe the business case.\n",
    "* How could Twitter data help a company decide how to spend its resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 403: Forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-64fbfcd68aa9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Content-Type'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'application/x-www-form-urlencoded'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accept'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'application/json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mdatajson\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0msentiment_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mattb/anaconda/lib/python3.5/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mattb/anaconda/lib/python3.5/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mattb/anaconda/lib/python3.5/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 582\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mattb/anaconda/lib/python3.5/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mattb/anaconda/lib/python3.5/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mattb/anaconda/lib/python3.5/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 403: Forbidden"
     ]
    }
   ],
   "source": [
    "from urllib.parse import urlencode\n",
    "from urllib.request import Request, urlopen\n",
    "import json\n",
    "\n",
    "sentiment_collection = db['sentiment']\n",
    "\n",
    "cursor = tweets_Collection.find()\n",
    "\n",
    "for document in cursor:\n",
    "    \n",
    "    screen_names = [ user_mention['screen_name']\n",
    "        for user_mention in document['entities']['user_mentions'] ]\n",
    "    # exclude tweets that mention both  realDonaldTrump and clinton from sentiment analysis.\n",
    "    # trying to associate postive/negative in such tweets to clinton or trump is byond this scope of this case.\n",
    "    if 'realDonaldTrump' in screen_names:\n",
    "        continue\n",
    "\n",
    "    # Iterate over the cleaned data - and process sentiment analysis on it. \n",
    "    url = 'https://japerk-text-processing.p.mashape.com/sentiment/' # Set destination URL here\n",
    "    post_fields = {'language': 'english', 'text' : document['text']}     # Set POST fields here\n",
    "\n",
    "    request = Request(url, urlencode(post_fields).encode())\n",
    "    # I put my credit card in this website - first 40000 calls are free - DONT EXCEED \n",
    "    request.add_header('X-Mashape-Key', '1z19gbsrAwmsh1EqYI3CcBbNtjOSp1T1iVIjsnRoFmszvbDkNV')\n",
    "    request.add_header('Content-Type', 'application/x-www-form-urlencoded')\n",
    "    request.add_header('Accept', 'application/json')\n",
    "    data = urlopen(request).read().decode()\n",
    "    datajson = json.loads(data)\n",
    "    sentiment_t = {}\n",
    "    if document['place']:\n",
    "        place = document['place']['full_name'].split()\n",
    "        sentiment_t['state'] = place[(len(place) - 1)]\n",
    "    sentiment_t['text'] = document['text']\n",
    "    sentiment_t['sentiment_label'] = datajson['label']\n",
    "    sentiment_t['entities'] = document['entities']\n",
    "    sentiment_json = json.loads(json.dumps(sentiment_t))\n",
    "    sentiment_collection.insert_one(sentiment_json)\n",
    "\n",
    "print (\"done\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print sumber of postive/negative postive ratio per state\n",
    "fields=['state', 'Postive ratio', 'Negative ratio']\n",
    "pt = PrettyTable(fields)\n",
    "pt.aligns = ['l' for f in fields]\n",
    "\n",
    "states_positive_ratio = {}\n",
    "sentiment_collection = db['sentiment']\n",
    "\n",
    "for state in us_states:\n",
    "    row = []\n",
    "    pos_count = sentiment_collection.find({'sentiment_label': 'pos', 'state':state}).count()\n",
    "    neg_count = sentiment_collection.find({'sentiment_label': 'neg', 'state':state}).count()\n",
    "    pos_ratio = 0\n",
    "    neg_ratio = 0\n",
    "    if pos_count + neg_count > 0:\n",
    "        pos_ratio = pos_count / (pos_count + neg_count) * 100\n",
    "        neg_ratio = neg_count / (pos_count + neg_count) * 100\n",
    "    row.append(state)\n",
    "    row.append(\"%.2f\" % pos_ratio)\n",
    "    row.append(\"%.2f\" % neg_ratio)\n",
    "    states_positive_ratio[state] = pos_ratio\n",
    "    pt.add_row(row)\n",
    "print(pt)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import folium\n",
    "import pandas as pd\n",
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "%matplotlib inline\n",
    "\n",
    "state_geo = r'us-states.json'\n",
    "\n",
    "sentiment_collection = db['sentiment']\n",
    "states_positive_ratio = {}\n",
    "for state in us_states:\n",
    "    pos_count = sentiment_collection.find({'sentiment_label': 'pos', 'state':state}).count()\n",
    "    neg_count = sentiment_collection.find({'sentiment_label': 'neg', 'state':state}).count()\n",
    "    pos_ratio = 0\n",
    "    if pos_count + neg_count > 0:\n",
    "        pos_ratio = pos_count / (pos_count + neg_count) * 100\n",
    "    states_positive_ratio[state] = pos_ratio\n",
    "\n",
    "map_data = states_positive_ratio\n",
    "\n",
    "map = folium.Map(location=(39, -100), zoom_start=4)\n",
    "#map = folium.Map(location=[48, -102], zoom_start=3)\n",
    "map.choropleth(geo_path=state_geo, data=map_data,\n",
    "             key_on='feature.id',\n",
    "             fill_color='BuPu', fill_opacity=0.8, line_opacity=0.6,\n",
    "             reset=False)\n",
    "print (\"the map should be shown below; if you can't see it, please find it in DS501map.html or re-run the first cell and the cell above\")\n",
    "map.save(\"DS501map.html\")\n",
    "HTML(map._repr_html_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## TODO use top entites defined in 2.3\n",
    "def print_top_hashtages(label, tweets, max_to_show):\n",
    "    \n",
    "    hashtags = [ hashtag['text'] \n",
    "         for tweet in tweets\n",
    "             for hashtag in tweet['entities']['hashtags'] ]\n",
    "    pt = PrettyTable(field_names=[label, 'Count'])\n",
    "    c = Counter(hashtags)\n",
    "    [ pt.add_row(kv) for kv in c.most_common()[:max_to_show] ]\n",
    "    pt.align[label], pt.align['Count'] = 'l', 'r' # Set column alignment\n",
    "    print(pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print top hastages in postive, negative and netural tweets\n",
    "\n",
    "sentiment_collection = db['sentiment']\n",
    "cursor = sentiment_collection.find({'sentiment_label': 'pos'})\n",
    "print_top_hashtages('Top Hashtage in POSTIVE Tweets', cursor, 20)\n",
    "\n",
    "cursor = sentiment_collection.find({'sentiment_label': 'neg'})\n",
    "print_top_hashtages('Top Hashtagein NEGATIVE Tweets', cursor, 20)\n",
    "\n",
    "cursor = sentiment_collection.find({'sentiment_label': 'neutral'})\n",
    "print_top_hashtages('Top Hashtage in NEUTRAL Tweets', cursor, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "TODO elaborate more!\n",
    "\n",
    "analyzing the hashtags distribution between positive and negative We find out that our sentiment NLP algorithm is not well trained - we need to train it again by using part of our data by classifying positive or negative for the training set based on hashtags.\n",
    "\n",
    "due to time constraints; we decide the make another positive/negative analysis based on selection set of hashtags from the top ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "postive_hashtags = [item.lower() for item in ['ImWithHer','TurnNCBlue','StrongerTogether']]\n",
    "negative_hashtags = [item.lower() for item in['WakeUpAmerica','NeverHillary','LatinosWithTrump','ImInHer','MAGA','CrookedHillary','AmericansUnitedForTrump','Im_in_Her']]\n",
    "\n",
    "# tweet that had both postive_hashtags & negative_hashtags will be ignored.\n",
    "# print top frequency words with postive_hashtags\n",
    "\n",
    "cursor = tweets_Collection.find()\n",
    "positive_tweets = []\n",
    "negative_tweets = []\n",
    "for document in cursor:\n",
    "    hashtags = [ hashtag['text'].lower() \n",
    "         for hashtag in document['entities']['hashtags'] ]\n",
    "    pos_count = len(set(postive_hashtags).intersection(hashtags))\n",
    "    neg_count = len(set(negative_hashtags).intersection(hashtags))\n",
    "    if (pos_count == 0 and neg_count == 0) or (pos_count > 0 and neg_count > 0):\n",
    "        continue\n",
    "    elif pos_count > 0:\n",
    "        positive_tweets.append(document)\n",
    "    else :\n",
    "        negative_tweets.append(document)\n",
    "        \n",
    "print(len(positive_tweets))\n",
    "print(len(negative_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print top hashtags for postive/negative tweets\n",
    "\n",
    "print_top_hashtages('Top Hashtagein POSITIVE Tweets - VERSION B', positive_tweets, 20)\n",
    "\n",
    "print_top_hashtages('Top Hashtage in NEGATIVE Tweets - VERSION B', negative_tweets, 20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*-----------------\n",
    "# Done\n",
    "\n",
    "All set! \n",
    "\n",
    "** What do you need to submit?**\n",
    "\n",
    "* **Notebook File**: Save this IPython notebook, and find the notebook file in your folder (for example, \"filename.ipynb\"). This is the file you need to submit. Please make sure all the plotted tables and figures are in the notebook. If you used \"ipython notebook --pylab=inline\" to open the notebook, all the figures and tables should have shown up in the notebook.\n",
    "\n",
    "\n",
    "* **PPT Slides**: please prepare PPT slides (for 10 minutes' talk) to present about the case study . We will ask two teams which are randomly selected to present their case studies in class for this case study. \n",
    "\n",
    "* ** Report**: please prepare a report (less than 10 pages) to report what you found in the data.\n",
    "    * What data you collected? \n",
    "    * Why this topic is interesting or important to you? (Motivations)\n",
    "    * How did you analyse the data?\n",
    "    * What did you find in the data? \n",
    " \n",
    "     (please include figures or tables in the report, but no source code)\n",
    "\n",
    "Please compress all the files in a zipped file.\n",
    "\n",
    "\n",
    "** How to submit: **\n",
    "\n",
    "        Please submit through email to Prof. Paffenroth (rcpaffenroth@wpi.edu) *and* the TA Wen Liu (wliu3@wpi.edu).\n",
    "        \n",
    "** Note: Each team just needs to submits one submission **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grading Criteria:\n",
    "\n",
    "** Totoal Points: 120 **\n",
    "\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "** Notebook:  **\n",
    "    Points: 80\n",
    "\n",
    "\n",
    "    -----------------------------------\n",
    "    Qestion 1:\n",
    "    Points: 20\n",
    "    -----------------------------------\n",
    "    \n",
    "    (1) Select a topic that you are interested in.\n",
    "    Points: 6 \n",
    "    \n",
    "    (2) Use Twitter Streaming API to sample a collection of tweets about this topic in real time. (It would be recommended that the number of tweets should be larger than 200, but smaller than 1 million. Please check whether the total number of tweets collected is larger than 200?\n",
    "    Points: 10 \n",
    "    \n",
    "    \n",
    "    (3) Store the tweets you downloaded into a local file (txt file or json file)\n",
    "    Points: 4 \n",
    "    \n",
    "    \n",
    "    -----------------------------------\n",
    "    Qestion 2:\n",
    "    Points: 20\n",
    "    -----------------------------------\n",
    "    \n",
    "    1. Word Count\n",
    "\n",
    "    (1) Use the tweets you collected in Problem 1, and compute the frequencies of the words being used in these tweets.\n",
    "    Points: 4 \n",
    "\n",
    "    (2) Plot a table of the top 30 words with their counts \n",
    "    Points: 4 \n",
    "    \n",
    "    2. Find the most popular tweets in your collection of tweets\n",
    "    plot a table of the top 10 tweets that are the most popular among your collection, i.e., the tweets with the largest number of retweet counts.\n",
    "    Points: 4 \n",
    "    \n",
    "    3. Find the most popular Tweet Entities in your collection of tweets\n",
    "\n",
    "    (1) plot a table of the top 10 hashtags, \n",
    "    Points: 4 \n",
    "\n",
    "    (2) top 10 user mentions that are the most popular in your collection of tweets.\n",
    "    Points: 4 \n",
    "    \n",
    "    \n",
    "    -----------------------------------\n",
    "    Qestion 3:\n",
    "    Points: 20\n",
    "    -----------------------------------\n",
    "    \n",
    "    (1) choose a popular twitter user who has many followers, such as \"ladygaga\".\n",
    "    Points: 4 \n",
    "\n",
    "    (2) Get the list of all friends and all followers of the twitter user.\n",
    "    Points: 4 \n",
    "\n",
    "    (3) Plot 20 out of the followers, plot their ID numbers and screen names in a table.\n",
    "    Points: 4 \n",
    "\n",
    "    (4) Plot 20 out of the friends (if the user has more than 20 friends), plot their ID numbers and screen names in a table.\n",
    "    Points: 4 \n",
    "    \n",
    "    (5) Compute the mutual friends within the two groups, i.e., the users who are in both friend list and follower list, plot their ID numbers and screen names in a table\n",
    "    Points: 4 \n",
    "  \n",
    "    -----------------------------------\n",
    "    Qestion 4:  Business question\n",
    "    Points: 20\n",
    "    -----------------------------------\n",
    "        Novelty: 10\n",
    "        Interestingness: 10\n",
    "    -----------------------------------\n",
    "    Run some additional experiments with your data to gain familiarity with the twitter data ant twitter API.  Come up with a business question and describe how Twitter data can help you answer that question.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "** Report: communicate the results**\n",
    "    Points: 20\n",
    "\n",
    "(1) What data you collected?\n",
    "    Points: 5 \n",
    "\n",
    "(2) Why this topic is interesting or important to you? (Motivations)\n",
    "    Points: 5 \n",
    "\n",
    "(3) How did you analyse the data?\n",
    "    Points: 5 \n",
    "\n",
    "(4) What did you find in the data?\n",
    "(please include figures or tables in the report, but no source code)\n",
    "    Points: 5 \n",
    "\n",
    "\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "** Slides (for 10 minutes of presentation): Story-telling **\n",
    "    Points: 20\n",
    "\n",
    "\n",
    "1. Motivation about the data collection, why the topic is interesting to you.\n",
    "    Points: 5 \n",
    "\n",
    "2. Communicating Results (figure/table)\n",
    "    Points: 10 \n",
    "\n",
    "3. Story telling (How all the parts (data, analysis, result) fit together as a story?)\n",
    "    Points: 5 \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
