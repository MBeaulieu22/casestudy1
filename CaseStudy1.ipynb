{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study 1 : Collecting Data from Twitter\n",
    "\n",
    "Due Date: September 22, **before the beginning of class at 6:00pm**\n",
    "\n",
    "* ------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/en/thumb/9/9f/Twitter_bird_logo_2012.svg/220px-Twitter_bird_logo_2012.svg.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TEAM Members:**\n",
    "\n",
    "    Matthew Beaulieu\n",
    "    \n",
    "    Yousef Fadila\n",
    "    \n",
    "    Meng Li\n",
    "    \n",
    "    Monica Tlachac\n",
    "    \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Required Readings:** \n",
    "* Chapter 1 and Chapter 9 of the book [Mining the Social Web](http://www.learndatasci.com/wp-content/uploads/2015/08/Mining-the-Social-Web-2nd-Edition.pdf) \n",
    "* The codes for [Chapter 1](http://bit.ly/1qCtMrr) and [Chapter 9](http://bit.ly/1u7eP33)\n",
    "\n",
    "\n",
    "** NOTE **\n",
    "* Please don't forget to save the notebook frequently when working in IPython Notebook, otherwise the changes you made can be lost.\n",
    "\n",
    "*----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Sampling Twitter Data with Streaming API about a certain topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Select a topic that you are interested in, for example, \"WPI\" or \"Lady Gaga\"\n",
    "* Use Twitter Streaming API to sample a collection of tweets about this topic in real time. (It would be recommended that the number of tweets should be larger than 200, but smaller than 1 million.\n",
    "* Store the tweets you downloaded into a local file (txt file or json file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import warnings\n",
    "import json\n",
    "import numpy as np\n",
    "import wikiwords\n",
    "from tweepy import Stream\n",
    "from tweepy.streaming import StreamListener\n",
    "import pymongo\n",
    "import tweepy\n",
    "import re\n",
    "\n",
    "warnings.simplefilter(action = \"ignore\", category = FutureWarning)\n",
    "%matplotlib inline\n",
    "#---------------------------------------------\n",
    "# Define a Function to Login Twitter API\n",
    "#\n",
    "# XXX  - DON'T COMMIT TRUE CREDINTIALS TO GITHUB\n",
    "CONSUMER_KEY = 'k01qrrsDSOHdjUObbt1pWjhld'\n",
    "CONSUMER_SECRET ='FTBSa4UU5Nxaw00hNPJQvoAf60HinJM87GfQpuFM0YsVKDdoJD'\n",
    "OAUTH_TOKEN = '4229853605-mSgVKfVSZ9BSN7GbPgvUIPOT1Xl6F3nA2ynKMvy'\n",
    "OAUTH_TOKEN_SECRET = 'jyHtNVKGmqNw4HyBLMYG5i9BT3junKGVFnY6CE2tjJRFW'\n",
    "\n",
    "# another set of auth to use when limit is hit.\n",
    "#CONSUMER_KEY = '7n45AnattFU5sb3MpbiwIoNYF'\n",
    "#CONSUMER_SECRET ='VtnEmlR99dG3hQ8FP8xb1TnomTAjSGkQYDJVhGa28IDPDEA2Cf'\n",
    "#OAUTH_TOKEN = '2497861306-W7d3EXegd4AY6jYt9ZaEz5rq5ZtguAAtp6KbseS'\n",
    "#OAUTH_TOKEN_SECRET = 'uv71S6pJwPibOFLA8WetoxWRb0nfqcQPK8f3ts30nEfQT'\n",
    "\n",
    "# mango db auth.\n",
    "MANGODB_SERVER = 'ds033046.mlab.com'\n",
    "MANGODB_PORT = 33046\n",
    "MANGODB_USER = 'ds501u'\n",
    "MANGODB_PASS = 'ds501p'\n",
    "MANGODB_NAME = 'ds501case1'\n",
    "MANGODB_COLLECTION = 'tweets'\n",
    "GEOBOX_USA = [-125,25.1,-60.5,49.1]\n",
    "\n",
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(OAUTH_TOKEN, OAUTH_TOKEN_SECRET)\n",
    "\n",
    "db_client = pymongo.MongoClient(MANGODB_SERVER, MANGODB_PORT)\n",
    "db = db_client[MANGODB_NAME]\n",
    "db.authenticate(MANGODB_USER, MANGODB_PASS)\n",
    "#----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "streaming done\n"
     ]
    }
   ],
   "source": [
    "class MyListener(StreamListener):\n",
    "    def __init__(self, max_count = 100):\n",
    "        self.count = 0\n",
    "        self.max_count = max_count   \n",
    "        self.collection = db[MANGODB_COLLECTION]\n",
    "\n",
    "    def on_data(self, data):\n",
    "        try:\n",
    "            if self.count >= self.max_count:\n",
    "                return False\n",
    "            # the question require output to file. so output to file and save in mangoDB\n",
    "            with open('data/hillary.json', 'a') as f:\n",
    "                f.write(data)\n",
    "            self.count = self.count + 1\n",
    "            datajson = json.loads(data)\n",
    "            self.collection.insert_one(datajson)\n",
    "            return True\n",
    "        except BaseException as e:\n",
    "            print(e)\n",
    "        return True\n",
    " \n",
    "    def on_error(self, status):\n",
    "        print(status)\n",
    "        return True\n",
    "    \n",
    "api = tweepy.API(auth)\n",
    "limit = 20000\n",
    "twitter_stream = Stream(auth, MyListener(limit))\n",
    "twitter_stream.filter(track=['@HillaryClinton'], languages=[\"en\"], locations=GEOBOX_USA)\n",
    "print(\"streaming done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report some statistics about the tweets you collected \n",
    "\n",
    "* The topic of interest: < INSERT YOUR TOPIC HERE>\n",
    "\n",
    "\n",
    "* The total number of tweets collected:  < INSERT THE NUMBER HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Analyzing Tweets and Tweet Entities with Frequency Analysis\n",
    "\n",
    "**1. Word Count:** \n",
    "* Use the tweets you collected in Problem 1, and compute the frequencies of the words being used in these tweets. \n",
    "* Plot a table of the top 30 words with their counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting Text from Tweets** \n",
    "\n",
    "* Get the text column of the tweet df\n",
    "* make it lower case\n",
    "* remove http links and non alphanum characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "################# RE WRITE THIS - DF is not defined in this context. define it or loop over database/file. your coice\n",
    "text = df.text.str.lower()\n",
    "for i,t in enumerate(text):\n",
    "    t = re.sub(r\"(?:\\@|https?\\://)\\S+\", \"\", t)\n",
    "    new = ''.join(e for e in t if (e.isalnum() or e==' '))\n",
    "    text[i] = new\n",
    "text = text.str.split(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a dictionary with each unique word as the key, and the number of times it appears as the value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_dict = {}\n",
    "for r in range(text.shape[0]):\n",
    "    lis = text.values[r]\n",
    "    for word in lis:\n",
    "        if word in word_dict.keys():\n",
    "            word_dict[word] +=1\n",
    "        else:\n",
    "            word_dict[word] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the key, value pairs to a dictionary (after removing rt, lingering https, and hillaryclinton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vals</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10186</th>\n",
       "      <td>4282</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5108</th>\n",
       "      <td>4097</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8577</th>\n",
       "      <td>2886</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4799</th>\n",
       "      <td>2681</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2245</th>\n",
       "      <td>2525</td>\n",
       "      <td>you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6185</th>\n",
       "      <td>2281</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>2036</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9372</th>\n",
       "      <td>1883</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5315</th>\n",
       "      <td>1666</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499</th>\n",
       "      <td>1575</td>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6598</th>\n",
       "      <td>1381</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6500</th>\n",
       "      <td>1295</td>\n",
       "      <td>her</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3348</th>\n",
       "      <td>1255</td>\n",
       "      <td>that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3649</th>\n",
       "      <td>1190</td>\n",
       "      <td>this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10058</th>\n",
       "      <td>1156</td>\n",
       "      <td>your</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>1103</td>\n",
       "      <td>she</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>1072</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4207</th>\n",
       "      <td>1061</td>\n",
       "      <td>are</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4255</th>\n",
       "      <td>993</td>\n",
       "      <td>trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6154</th>\n",
       "      <td>968</td>\n",
       "      <td>amp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8735</th>\n",
       "      <td>915</td>\n",
       "      <td>hillary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3778</th>\n",
       "      <td>898</td>\n",
       "      <td>has</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11397</th>\n",
       "      <td>898</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7039</th>\n",
       "      <td>855</td>\n",
       "      <td>not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10429</th>\n",
       "      <td>797</td>\n",
       "      <td>we</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2785</th>\n",
       "      <td>787</td>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10681</th>\n",
       "      <td>751</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9491</th>\n",
       "      <td>717</td>\n",
       "      <td>with</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>684</td>\n",
       "      <td>what</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8640</th>\n",
       "      <td>654</td>\n",
       "      <td>about</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       vals    words\n",
       "10186  4282       to\n",
       "5108   4097      the\n",
       "8577   2886       is\n",
       "4799   2681        a\n",
       "2245   2525      you\n",
       "6185   2281       of\n",
       "264    2036      for\n",
       "9372   1883       in\n",
       "5315   1666      and\n",
       "7499   1575       on\n",
       "6598   1381        i\n",
       "6500   1295      her\n",
       "3348   1255     that\n",
       "3649   1190     this\n",
       "10058  1156     your\n",
       "764    1103      she\n",
       "576    1072       it\n",
       "4207   1061      are\n",
       "4255    993    trump\n",
       "6154    968      amp\n",
       "8735    915  hillary\n",
       "3778    898      has\n",
       "11397   898      all\n",
       "7039    855      not\n",
       "10429   797       we\n",
       "2785    787       be\n",
       "10681   751       no\n",
       "9491    717     with\n",
       "721     684     what\n",
       "8640    654    about"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals = []\n",
    "remove_list = ['', ' ', 'rt', 'http','https','hillaryclinton']\n",
    "keys = [ e for e in word_dict.keys() if e not in remove_list]\n",
    "for key in keys:\n",
    "    vals.append(word_dict.get(key))\n",
    "    \n",
    "tweet_df = pd.DataFrame({'words':keys, 'vals':vals})\n",
    "tweet_df = tweet_df.sort_values('vals', ascending=False)\n",
    "tweet_df[0:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon first anlysis, the 30 most used words in the tweets we pulled are pretty common, with special cases such as \"hillary\", and \"trump\".  \n",
    "\n",
    "The next strategy was to normalize each tweet for how popular it is in the English language, to find a more interesting top word count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vals</th>\n",
       "      <th>words</th>\n",
       "      <th>freq</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6154</th>\n",
       "      <td>968</td>\n",
       "      <td>amp</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>2.649444e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8935</th>\n",
       "      <td>391</td>\n",
       "      <td>hypocrisy</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2.041077e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4255</th>\n",
       "      <td>993</td>\n",
       "      <td>trump</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1.673466e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8735</th>\n",
       "      <td>915</td>\n",
       "      <td>hillary</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1.660476e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>236</td>\n",
       "      <td>unfit</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.062605e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5565</th>\n",
       "      <td>104</td>\n",
       "      <td>yells</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.025306e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6215</th>\n",
       "      <td>290</td>\n",
       "      <td>stunning</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>8.027490e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4732</th>\n",
       "      <td>97</td>\n",
       "      <td>yrs</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>7.345456e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10006</th>\n",
       "      <td>115</td>\n",
       "      <td>bodyguards</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>7.057417e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3828</th>\n",
       "      <td>82</td>\n",
       "      <td>benghazi</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>6.487133e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3585</th>\n",
       "      <td>207</td>\n",
       "      <td>doesnt</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.278809e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>268</td>\n",
       "      <td>cant</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>6.045840e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10098</th>\n",
       "      <td>94</td>\n",
       "      <td>didnt</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>5.126433e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>86</td>\n",
       "      <td>trumps</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>4.904659e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10810</th>\n",
       "      <td>94</td>\n",
       "      <td>wont</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>4.811936e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6356</th>\n",
       "      <td>91</td>\n",
       "      <td>poorest</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>4.258990e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11272</th>\n",
       "      <td>42</td>\n",
       "      <td>dnc</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>4.021426e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6890</th>\n",
       "      <td>412</td>\n",
       "      <td>lets</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>3.826785e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1354</th>\n",
       "      <td>75</td>\n",
       "      <td>whats</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>3.786318e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11141</th>\n",
       "      <td>104</td>\n",
       "      <td>realises</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>3.763119e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7265</th>\n",
       "      <td>142</td>\n",
       "      <td>liar</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>3.719576e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5121</th>\n",
       "      <td>73</td>\n",
       "      <td>blackmail</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>3.535690e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8823</th>\n",
       "      <td>36</td>\n",
       "      <td>tweet</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.457496e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5357</th>\n",
       "      <td>389</td>\n",
       "      <td>dont</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>3.437822e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6304</th>\n",
       "      <td>148</td>\n",
       "      <td>pneumonia</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>3.434423e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>55</td>\n",
       "      <td>footing</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>3.303236e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1728</th>\n",
       "      <td>35</td>\n",
       "      <td>audiobook</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.113467e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8661</th>\n",
       "      <td>180</td>\n",
       "      <td>thats</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>3.059080e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4041</th>\n",
       "      <td>63</td>\n",
       "      <td>isnt</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2.780705e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4982</th>\n",
       "      <td>128</td>\n",
       "      <td>donors</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>2.747749e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       vals       words      freq         ratio\n",
       "6154    968         amp  0.000004  2.649444e+08\n",
       "8935    391   hypocrisy  0.000002  2.041077e+08\n",
       "4255    993       trump  0.000006  1.673466e+08\n",
       "8735    915     hillary  0.000006  1.660476e+08\n",
       "2046    236       unfit  0.000002  1.062605e+08\n",
       "5565    104       yells  0.000001  1.025306e+08\n",
       "6215    290    stunning  0.000004  8.027490e+07\n",
       "4732     97         yrs  0.000001  7.345456e+07\n",
       "10006   115  bodyguards  0.000002  7.057417e+07\n",
       "3828     82    benghazi  0.000001  6.487133e+07\n",
       "3585    207      doesnt  0.000003  6.278809e+07\n",
       "1674    268        cant  0.000004  6.045840e+07\n",
       "10098    94       didnt  0.000002  5.126433e+07\n",
       "2197     86      trumps  0.000002  4.904659e+07\n",
       "10810    94        wont  0.000002  4.811936e+07\n",
       "6356     91     poorest  0.000002  4.258990e+07\n",
       "11272    42         dnc  0.000001  4.021426e+07\n",
       "6890    412        lets  0.000011  3.826785e+07\n",
       "1354     75       whats  0.000002  3.786318e+07\n",
       "11141   104    realises  0.000003  3.763119e+07\n",
       "7265    142        liar  0.000004  3.719576e+07\n",
       "5121     73   blackmail  0.000002  3.535690e+07\n",
       "8823     36       tweet  0.000001  3.457496e+07\n",
       "5357    389        dont  0.000011  3.437822e+07\n",
       "6304    148   pneumonia  0.000004  3.434423e+07\n",
       "1265     55     footing  0.000002  3.303236e+07\n",
       "1728     35   audiobook  0.000001  3.113467e+07\n",
       "8661    180       thats  0.000006  3.059080e+07\n",
       "4041     63        isnt  0.000002  2.780705e+07\n",
       "4982    128      donors  0.000005  2.747749e+07"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wikiwords is a cool library that tells how often a word appears in wikipedia articles\n",
    "# and works to normalize for word popularity\n",
    "tweet_df['freq'] = tweet_df['words'].apply(wikiwords.freq)\n",
    "tweet_df = tweet_df[tweet_df['freq'] > 1.0e-6]\n",
    "tweet_df['ratio'] = tweet_df['vals'] / tweet_df['freq']\n",
    "tweet_df.sort_values('ratio', ascending=False)[0:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This list is much more interesting, with words like Benghazi, stunning, hypocrisy, and unfit, seeming like more specific to the subject being discussed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Find the most popular tweets in your collection of tweets**\n",
    "\n",
    "Please plot a table of the top 10 tweets that are the most popular among your collection, i.e., the tweets with the largest number of retweet counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the tweets are already loaded into a Pandas DataFrame, this part should be pretty straightforward..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@BoyGeorge @HillaryClinton Don't be sorry for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9659</th>\n",
       "      <td>0</td>\n",
       "      <td>@HillaryClinton get off my feed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9660</th>\n",
       "      <td>0</td>\n",
       "      <td>RT @Delo_Taylor: After 8 yrs of neglect all @P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9661</th>\n",
       "      <td>0</td>\n",
       "      <td>Please retweet twitter blocking comments https...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9662</th>\n",
       "      <td>0</td>\n",
       "      <td>@ClintonFdn @HillaryClinton \\n\\nhttps://t.co/y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9663</th>\n",
       "      <td>0</td>\n",
       "      <td>RT @Bikers4Trump: After the 3 Terrorist Attack...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9664</th>\n",
       "      <td>0</td>\n",
       "      <td>@BarbaraAResEsq @Cuckerella let's not forget @...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9665</th>\n",
       "      <td>0</td>\n",
       "      <td>RT @FoxNews: .@JudgeJeanine to @HillaryClinton...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9666</th>\n",
       "      <td>0</td>\n",
       "      <td>RT @Someweirdid: @BrianAbelTV @HillaryClinton ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9667</th>\n",
       "      <td>0</td>\n",
       "      <td>@HillaryClinton At some point you MUST address...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      retweet_count                                               text\n",
       "0                 0  @BoyGeorge @HillaryClinton Don't be sorry for ...\n",
       "9659              0                    @HillaryClinton get off my feed\n",
       "9660              0  RT @Delo_Taylor: After 8 yrs of neglect all @P...\n",
       "9661              0  Please retweet twitter blocking comments https...\n",
       "9662              0  @ClintonFdn @HillaryClinton \\n\\nhttps://t.co/y...\n",
       "9663              0  RT @Bikers4Trump: After the 3 Terrorist Attack...\n",
       "9664              0  @BarbaraAResEsq @Cuckerella let's not forget @...\n",
       "9665              0  RT @FoxNews: .@JudgeJeanine to @HillaryClinton...\n",
       "9666              0  RT @Someweirdid: @BrianAbelTV @HillaryClinton ...\n",
       "9667              0  @HillaryClinton At some point you MUST address..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values('retweet_count', ascending='False')[['retweet_count', 'text']][0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, these tweets were pulled from the twitter streaming API, meaning we saved the tweets as they appeared, and before they were retweeted or favorited by any of the user base.\n",
    "\n",
    "To fix this, we pulled 1/10 of them again from the REST API (not the whole set due to rate limits), saved it to a JSON, loaded it to a df, and ran the command again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lst = []\n",
    "with open('data/update_hillary.json', 'r') as f:\n",
    "    for line in f:\n",
    "        tweet = json.loads(line)\n",
    "        lst.append(tweet)\n",
    "new_df = pd.DataFrame(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>{'screen_name': 'Kelly4220', 'followers_count'...</td>\n",
       "      <td>17540</td>\n",
       "      <td>RT @YoungDems4Trump: Show this to those who do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>{'screen_name': 'GoWithItJam', 'followers_coun...</td>\n",
       "      <td>6426</td>\n",
       "      <td>RT @bfraser747: 💥💥 BREAKING NEWS  💥💥\\n\\nNobody...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>{'screen_name': 'HijaOfPromise', 'followers_co...</td>\n",
       "      <td>2149</td>\n",
       "      <td>RT @SenGillibrand: Love this.\\n\\n\"@HillaryClin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>{'screen_name': 'winwarchr', 'followers_count'...</td>\n",
       "      <td>2076</td>\n",
       "      <td>RT @Harlan: Whoa, this is a BRUTAL take on @Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>{'screen_name': 'newstheone', 'followers_count...</td>\n",
       "      <td>1804</td>\n",
       "      <td>RT @RealBenCarson: @HillaryClinton hiding her ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>{'screen_name': 'trolymcmemeface', 'followers_...</td>\n",
       "      <td>1758</td>\n",
       "      <td>RT @DrJillStein: Obama admin including @Hillar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>{'screen_name': 'ofie007', 'followers_count': ...</td>\n",
       "      <td>1587</td>\n",
       "      <td>RT @FoxNews: Fox News Poll: @realDonaldTrump l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>{'screen_name': '3085', 'followers_count': 277...</td>\n",
       "      <td>1586</td>\n",
       "      <td>RT @FoxNews: Fox News Poll: @realDonaldTrump l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>{'screen_name': 'LifeLessonsApp', 'followers_c...</td>\n",
       "      <td>1392</td>\n",
       "      <td>RT @Jorge_Silva: Celebrating #HispanicHeritage...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>{'screen_name': 'I_am_Deplorable', 'followers_...</td>\n",
       "      <td>1385</td>\n",
       "      <td>RT @ImWithYou010: @hillaryclinton talking abou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   user  retweet_count  \\\n",
       "605   {'screen_name': 'Kelly4220', 'followers_count'...          17540   \n",
       "837   {'screen_name': 'GoWithItJam', 'followers_coun...           6426   \n",
       "1106  {'screen_name': 'HijaOfPromise', 'followers_co...           2149   \n",
       "1100  {'screen_name': 'winwarchr', 'followers_count'...           2076   \n",
       "615   {'screen_name': 'newstheone', 'followers_count...           1804   \n",
       "402   {'screen_name': 'trolymcmemeface', 'followers_...           1758   \n",
       "969   {'screen_name': 'ofie007', 'followers_count': ...           1587   \n",
       "666   {'screen_name': '3085', 'followers_count': 277...           1586   \n",
       "1131  {'screen_name': 'LifeLessonsApp', 'followers_c...           1392   \n",
       "465   {'screen_name': 'I_am_Deplorable', 'followers_...           1385   \n",
       "\n",
       "                                                   text  \n",
       "605   RT @YoungDems4Trump: Show this to those who do...  \n",
       "837   RT @bfraser747: 💥💥 BREAKING NEWS  💥💥\\n\\nNobody...  \n",
       "1106  RT @SenGillibrand: Love this.\\n\\n\"@HillaryClin...  \n",
       "1100  RT @Harlan: Whoa, this is a BRUTAL take on @Hi...  \n",
       "615   RT @RealBenCarson: @HillaryClinton hiding her ...  \n",
       "402   RT @DrJillStein: Obama admin including @Hillar...  \n",
       "969   RT @FoxNews: Fox News Poll: @realDonaldTrump l...  \n",
       "666   RT @FoxNews: Fox News Poll: @realDonaldTrump l...  \n",
       "1131  RT @Jorge_Silva: Celebrating #HispanicHeritage...  \n",
       "465   RT @ImWithYou010: @hillaryclinton talking abou...  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop duplicates is used because on retweeted tweets, twitter stores\n",
    "# the retweet count from the source tweet, for all of them, so there were several repeats\n",
    "new_df.sort_values('retweet_count', ascending=False)[['user', 'retweet_count', 'text']][0:100].drop_duplicates('retweet_count')[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pulled ~1000 of our tweets from the rest API after they'd existed for a period of time, and could be retweeted. These are the 10 most popular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Find the most popular Tweet Entities in your collection of tweets**\n",
    "\n",
    "Please plot a table of the top 10 hashtags, top 10 user mentions that are the most popular in your collection of tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ------------------------\n",
    "\n",
    "# Problem 3: Getting \"All\" friends and \"All\" followers of a popular user in twitter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* choose a popular twitter user who has many followers, such as \"ladygaga\".\n",
    "* Get the list of all friends and all followers of the twitter user.\n",
    "* Plot 20 out of the followers, plot their ID numbers and screen names in a table.\n",
    "* Plot 20 out of the friends (if the user has more than 20 friends), plot their ID numbers and screen names in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#definitios and config values\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "MANGODB_SERVER = 'ds035816.mlab.com'\n",
    "MANGODB_PORT = 35816\n",
    "MANGODB_CLINTON_FF_DB_NAME = \"clintonff\"\n",
    "MANGODB_CLINTON_FF_COLL = \"collection\"\n",
    "db_clinton_ff_client = pymongo.MongoClient(MANGODB_SERVER, MANGODB_PORT)\n",
    "db_clinton_ff = db_clinton_ff_client[MANGODB_CLINTON_FF_DB_NAME]\n",
    "db_clinton_ff.authenticate(MANGODB_USER, MANGODB_PASS)  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fetch all followers \n",
    "\n",
    "data_followers = {}\n",
    "data_followers['type'] = 'followers'\n",
    "data_followers['lst'] = []\n",
    "cur = tweepy.Cursor(api.followers_ids, id = 'HillaryClinton').pages()\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        data_followers['lst'] = cur.next()[:]\n",
    "        followers_json = json.loads(json.dumps(data_followers))\n",
    "        db_clinton_ff[MANGODB_CLINTON_FF_COLL].insert_one(followers_json)\n",
    "        del data_followers['lst'][:]     \n",
    "    except tweepy.TweepError:\n",
    "        time.sleep(60 * 15 + 10)\n",
    "        continue\n",
    "    except StopIteration:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fetch all friends\n",
    "#no need for iteration like fetching followers as number of friends is relatvely small\n",
    "data_friends = {}\n",
    "data_friends['type'] = 'friends'\n",
    "data_friends['lst'] = []\n",
    "\n",
    "# fetch all friends list - as this list relativly samll we won't hit the limit here.\n",
    "\n",
    "friends_ids = []     \n",
    "for itm in tweepy.Cursor(api.friends_ids, id = 'HillaryClinton').items():\n",
    "    data_friends['lst'].append(itm)\n",
    "\n",
    "# save the friend's list in mangoDB    \n",
    "friends_json = json.loads(json.dumps(data_friends))  \n",
    "db_clinton_ff[MANGODB_CLINTON_FF_COLL].insert_one(friends_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "# Given a set of user ids, this function calls get_screen_names and plots a table of the first (max_ids) ID's and screen names.\n",
    "def draw_pretty_table(ids):\n",
    "    users = api.lookup_users(user_ids=ids)\n",
    "    pretty_table = PrettyTable(['ID','Screen Name'])\n",
    "    [pretty_table.add_row ([row.id,row.screen_name]) for row in users]\n",
    "    pretty_table.align = 'l'\n",
    "    print(pretty_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print 20 firends and 20 followers data\n",
    "#\n",
    "cursor = db_clinton_ff[MANGODB_CLINTON_FF_COLL].find({\"type\": \"friends\"})\n",
    "print (\"\\n20 friends of Hilary Clinton\\n\")\n",
    "draw_pretty_table(cursor[0]['lst'][:20])\n",
    "\n",
    "cursor = db_clinton_ff[MANGODB_CLINTON_FF_COLL].find({\"type\": \"followers\"})\n",
    "print (\"\\n20 followers of Hilary Clinton\\n\")\n",
    "draw_pretty_table(cursor[0]['lst'][:20])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compute the mutual friends within the two groups, i.e., the users who are in both friend list and follower list, plot their ID numbers and screen names in a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutual Friends table\n",
      "+--------------------+----------------+\n",
      "| ID                 | Screen Name    |\n",
      "+--------------------+----------------+\n",
      "| 3068729259         | HillaryforND   |\n",
      "| 3065862285         | HillaryforNJ   |\n",
      "| 172858784          | timkaine       |\n",
      "| 3064597541         | HillaryforMO   |\n",
      "| 3044781131         | HillaryforAR   |\n",
      "| 3073392597         | HillaryforSD   |\n",
      "| 3078554829         | HillaryforTX   |\n",
      "| 3057577828         | HillaryforIN   |\n",
      "| 3073477156         | HillaryforTN   |\n",
      "| 99545933           | mouto77        |\n",
      "| 3086798481         | HillaryforWV   |\n",
      "| 3044746419         | HillaryforCA   |\n",
      "| 3047899581         | HillaryforCT   |\n",
      "| 758346398156881920 | HRCforRI       |\n",
      "| 3060191026         | HillaryforMA   |\n",
      "| 3057542915         | HillaryforKY   |\n",
      "| 3048168670         | HillaryforDE   |\n",
      "| 3060143603         | HillaryforMD   |\n",
      "| 139939973          | jpbmayor       |\n",
      "| 4884965834         | HillaryforUT   |\n",
      "| 755024857373474816 | Hillary_esp    |\n",
      "| 3044710461         | HillaryforAZ   |\n",
      "| 3031619171         | HillaryforAL   |\n",
      "| 3058863113         | HillaryforLA   |\n",
      "| 3068825260         | HillaryforOK   |\n",
      "| 3068783345         | HillaryforOR   |\n",
      "| 3052911538         | HillaryForGA   |\n",
      "| 3065982773         | HillaryforNM   |\n",
      "| 1287341107         | DaveTencza     |\n",
      "| 31393043           | NHkaren        |\n",
      "| 83668232           | JesseFFerguson |\n",
      "| 23449384           | amberdiscko    |\n",
      "| 8370082            | DemConvention  |\n",
      "| 3061981559         | HillaryforMI   |\n",
      "| 747148719225610240 | gsanchofl      |\n",
      "| 746719903210737664 | VallveRendi    |\n",
      "| 746432638701834240 | Scherlie_      |\n",
      "| 130288787          | DevanQuinn     |\n",
      "| 43703569           | peggygilmour   |\n",
      "| 59238835           | GarthCorriveau |\n",
      "| 1033943323         | sueford06      |\n",
      "| 1931494634         | ezradf         |\n",
      "| 25238413           | MollyMurph     |\n",
      "| 3081659314         | HillaryforVA   |\n",
      "| 3065967867         | HillaryforNC   |\n",
      "| 3068811118         | HillaryforOH   |\n",
      "| 41021335           | TroyClair      |\n",
      "| 12434632           | wssrstrm       |\n",
      "| 3088855679         | HillaryforWI   |\n",
      "+--------------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "cursor = db_clinton_ff[MANGODB_CLINTON_FF_COLL].find({\"type\": \"friends\"})\n",
    "friends = cursor[0]['lst']\n",
    "cursor = db_clinton_ff[MANGODB_CLINTON_FF_COLL].find({\"type\": \"followers\"})\n",
    "\n",
    "# we have 1 list of friends (~800 members) and over 500 list of followers; each of 5000 members,\n",
    "#iterate over the followers and build the intersaction list\n",
    "common_friends = []\n",
    "total = 0\n",
    "for follower in cursor:\n",
    "    common_friends.extend(set(friends).intersection(follower['lst']))\n",
    "    total += len(follower['lst'])\n",
    "    \n",
    "#print ('Clinton has {} followers; {} following ; {} mutal friends'.format(total, len(friends), len(common_friends)))\n",
    "print(\"This list is not a complete one as it requires about 30 hours to fetch all followers of \\n Clinto due to twitter rate limit\\n we fetched about 4M out of 8M followers\\n\")\n",
    "print (\"Mutual Friends table\")\n",
    "draw_pretty_table(common_friends)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*------------------------\n",
    "\n",
    "# Problem 4: Business question \n",
    "\n",
    "Run some additional experiments with your data to gain familiarity with the twitter data and twitter API.\n",
    "\n",
    "* Come up with a business question that Twitter data could help answer.\n",
    "* Decribe the business case.\n",
    "* How could Twitter data help a company decide how to spend its resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yousef:36242 t 5157\n"
     ]
    }
   ],
   "source": [
    "# remove this cell before submission - this is only to sync files with DB\n",
    "\n",
    "lst = []\n",
    "s = 0\n",
    "t = 0\n",
    "db_client = pymongo.MongoClient(MANGODB_SERVER, MANGODB_PORT)\n",
    "db = db_client[MANGODB_NAME]\n",
    "db.authenticate(MANGODB_USER, MANGODB_PASS)      \n",
    "db_collection = db[MANGODB_COLLECTION]\n",
    "        \n",
    "with open('data/hillary.json', 'r') as f:\n",
    "    for line in f:\n",
    "        try:\n",
    "            line = line.strip(' \\t\\n\\r')\n",
    "            tweet = json.loads(line)\n",
    "            db_collection.insert_one(tweet)\n",
    "            t = t + 1\n",
    "        except ValueError:\n",
    "            s = s + 1 \n",
    "\n",
    "print(\"yousef:\" + str(s) + \" t \" + str(t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from urllib.parse import urlencode\n",
    "from urllib.request import Request, urlopen\n",
    "import json\n",
    "\n",
    "tweets_Collection = db[MANGODB_COLLECTION]\n",
    "#tweets_Collection = db['cleaned_tweets']\n",
    "sentiment_collection = db['sentiment']\n",
    "\n",
    "cursor = tweets_Collection.find()\n",
    "\n",
    "for document in cursor:\n",
    "    \n",
    "    screen_names = [ user_mention['screen_name']\n",
    "        for user_mention in document['entities']['user_mentions'] ]\n",
    "    # exclude tweets that mention both  realDonaldTrump and clinton from sentiment analysis.\n",
    "    # trying to associate postive/negative in such tweets to clinton or trump is byond this scope of this case.\n",
    "    if 'realDonaldTrump' in screen_names:\n",
    "        continue\n",
    "\n",
    "    # Iterate over the cleaned data - and process sentiment analysis on it. \n",
    "    url = 'https://japerk-text-processing.p.mashape.com/sentiment/' # Set destination URL here\n",
    "    post_fields = {'language': 'english', 'text' : document['text']}     # Set POST fields here\n",
    "\n",
    "    request = Request(url, urlencode(post_fields).encode())\n",
    "    # I put my credit card in this website - first 40000 calls are free - DONT EXCEED \n",
    "    request.add_header('X-Mashape-Key', '1z19gbsrAwmsh1EqYI3CcBbNtjOSp1T1iVIjsnRoFmszvbDkNV')\n",
    "    request.add_header('Content-Type', 'application/x-www-form-urlencoded')\n",
    "    request.add_header('Accept', 'application/json')\n",
    "    data = urlopen(request).read().decode()\n",
    "    datajson = json.loads(data)\n",
    "    sentiment_t = {}\n",
    "    if document['place']:\n",
    "        place = document['place']['full_name'].split()\n",
    "        sentiment_t['state'] = place[(len(place) - 1)]\n",
    "    sentiment_t['text'] = document['text']\n",
    "    sentiment_t['sentiment_label'] = datajson['label']\n",
    "    sentiment_t['entities'] = document['entities']\n",
    "    sentiment_json = json.loads(json.dumps(sentiment_t))\n",
    "    sentiment_collection.insert_one(sentiment_json)\n",
    "\n",
    "print (\"done\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# example how to get the state from the tweet.\n",
    "lst = []\n",
    "states = []\n",
    "with open('data/hillary.json', 'r') as f:\n",
    "    for line in f:\n",
    "        tweet = json.loads(line)\n",
    "        lst.append(tweet)\n",
    "\n",
    "states = [tweeet['place']['full_name'].split()\n",
    "         for tweeet in lst if tweeet['place']]\n",
    "\n",
    "states = [x[len(x) - 1] for x in states if x[(len(x) - 1)] != 'USA']      \n",
    "df = pd.DataFrame(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import folium\n",
    "import pandas as pd\n",
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "%matplotlib inline\n",
    "\n",
    "state_geo = r'us-states.json'\n",
    "clinton_popularity_str = '{\"WA\": 7.8, \"DE\": 7.1, \"WI\": 6.8, \"WV\": 7.5, \"HI\": 5.4, \"FL\": 8.2, \"WY\": 5.1, \"NH\": 5.7, \"NJ\": 9.6, \"NM\": 6.8, \"TX\": 10, \"LA\": 5.9, \"NC\": 9.4, \"ND\": 3.2, \"NE\": 3.9, \"TN\": 7.8, \"NY\": 8.4, \"PA\": 8.0, \"CA\": 10.1, \"NV\": 10.3, \"VA\": 5.8, \"CO\": 7.7, \"AK\": 6.8, \"AL\": 7.1, \"AR\": 7.2, \"VT\": 5.0, \"IL\": 8.8, \"GA\": 8.8, \"IN\": 8.4, \"IA\": 5.1, \"OK\": 5.2, \"AZ\": 8.1, \"ID\": 6.6, \"CT\": 8.4, \"ME\": 7.2, \"MD\": 6.8, \"MA\": 6.7, \"OH\": 6.9, \"UT\": 5.5, \"MO\": 6.7, \"MN\": 5.6, \"MI\": 9.1, \"RI\": 10.1, \"KS\": 5.6, \"MT\": 5.8, \"MS\": 9.1, \"SC\": 8.8, \"KY\": 8.1, \"OR\": 8.5, \"SD\": 4.4}' \n",
    "clinton_popularity_json = json.loads(clinton_popularity_str)\n",
    "\n",
    "map = folium.Map(location=(39, -100), zoom_start=4)\n",
    "#map = folium.Map(location=[48, -102], zoom_start=3)\n",
    "map.choropleth(geo_path=state_geo, data=clinton_popularity_json,\n",
    "             key_on='feature.id',\n",
    "             fill_color='BuPu', fill_opacity=0.8, line_opacity=0.6,\n",
    "             reset=False)\n",
    "print (\"the map should be shown below; if you can't see it, please find it in DS501map.html or re-run the cell\")\n",
    "map.save(\"DS501map.html\")\n",
    "HTML(map._repr_html_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "def print_top_hashtages(label, tweets, max_to_show):\n",
    "    \n",
    "    hashtags = [ hashtag['text'] \n",
    "         for tweet in tweets\n",
    "             for hashtag in tweet['entities']['hashtags'] ]\n",
    "    pt = PrettyTable(field_names=[label, 'Count'])\n",
    "    c = Counter(hashtags)\n",
    "    [ pt.add_row(kv) for kv in c.most_common()[:max_to_show] ]\n",
    "    pt.align[label], pt.align['Count'] = 'l', 'r' # Set column alignment\n",
    "    print(pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print top hastages in postive and negative tweets\n",
    "\n",
    "sentiment_collection = db['sentiment']\n",
    "cursor = sentiment_collection.find({'sentiment_label': 'pos'})\n",
    "print_top_hashtages('top hashtages in POSTIVE tweets', cursor, 10)\n",
    "\n",
    "print (\"\\n\\n\")\n",
    "cursor = sentiment_collection.find({'sentiment_label': 'neg'})\n",
    "print_top_hashtages('top hashtages in NEGATIVE tweets', cursor, 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*-----------------\n",
    "# Done\n",
    "\n",
    "All set! \n",
    "\n",
    "** What do you need to submit?**\n",
    "\n",
    "* **Notebook File**: Save this IPython notebook, and find the notebook file in your folder (for example, \"filename.ipynb\"). This is the file you need to submit. Please make sure all the plotted tables and figures are in the notebook. If you used \"ipython notebook --pylab=inline\" to open the notebook, all the figures and tables should have shown up in the notebook.\n",
    "\n",
    "\n",
    "* **PPT Slides**: please prepare PPT slides (for 10 minutes' talk) to present about the case study . We will ask two teams which are randomly selected to present their case studies in class for this case study. \n",
    "\n",
    "* ** Report**: please prepare a report (less than 10 pages) to report what you found in the data.\n",
    "    * What data you collected? \n",
    "    * Why this topic is interesting or important to you? (Motivations)\n",
    "    * How did you analyse the data?\n",
    "    * What did you find in the data? \n",
    " \n",
    "     (please include figures or tables in the report, but no source code)\n",
    "\n",
    "Please compress all the files in a zipped file.\n",
    "\n",
    "\n",
    "** How to submit: **\n",
    "\n",
    "        Please submit through email to Prof. Paffenroth (rcpaffenroth@wpi.edu) *and* the TA Wen Liu (wliu3@wpi.edu).\n",
    "        \n",
    "** Note: Each team just needs to submits one submission **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grading Criteria:\n",
    "\n",
    "** Totoal Points: 120 **\n",
    "\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "** Notebook:  **\n",
    "    Points: 80\n",
    "\n",
    "\n",
    "    -----------------------------------\n",
    "    Qestion 1:\n",
    "    Points: 20\n",
    "    -----------------------------------\n",
    "    \n",
    "    (1) Select a topic that you are interested in.\n",
    "    Points: 6 \n",
    "    \n",
    "    (2) Use Twitter Streaming API to sample a collection of tweets about this topic in real time. (It would be recommended that the number of tweets should be larger than 200, but smaller than 1 million. Please check whether the total number of tweets collected is larger than 200?\n",
    "    Points: 10 \n",
    "    \n",
    "    \n",
    "    (3) Store the tweets you downloaded into a local file (txt file or json file)\n",
    "    Points: 4 \n",
    "    \n",
    "    \n",
    "    -----------------------------------\n",
    "    Qestion 2:\n",
    "    Points: 20\n",
    "    -----------------------------------\n",
    "    \n",
    "    1. Word Count\n",
    "\n",
    "    (1) Use the tweets you collected in Problem 1, and compute the frequencies of the words being used in these tweets.\n",
    "    Points: 4 \n",
    "\n",
    "    (2) Plot a table of the top 30 words with their counts \n",
    "    Points: 4 \n",
    "    \n",
    "    2. Find the most popular tweets in your collection of tweets\n",
    "    plot a table of the top 10 tweets that are the most popular among your collection, i.e., the tweets with the largest number of retweet counts.\n",
    "    Points: 4 \n",
    "    \n",
    "    3. Find the most popular Tweet Entities in your collection of tweets\n",
    "\n",
    "    (1) plot a table of the top 10 hashtags, \n",
    "    Points: 4 \n",
    "\n",
    "    (2) top 10 user mentions that are the most popular in your collection of tweets.\n",
    "    Points: 4 \n",
    "    \n",
    "    \n",
    "    -----------------------------------\n",
    "    Qestion 3:\n",
    "    Points: 20\n",
    "    -----------------------------------\n",
    "    \n",
    "    (1) choose a popular twitter user who has many followers, such as \"ladygaga\".\n",
    "    Points: 4 \n",
    "\n",
    "    (2) Get the list of all friends and all followers of the twitter user.\n",
    "    Points: 4 \n",
    "\n",
    "    (3) Plot 20 out of the followers, plot their ID numbers and screen names in a table.\n",
    "    Points: 4 \n",
    "\n",
    "    (4) Plot 20 out of the friends (if the user has more than 20 friends), plot their ID numbers and screen names in a table.\n",
    "    Points: 4 \n",
    "    \n",
    "    (5) Compute the mutual friends within the two groups, i.e., the users who are in both friend list and follower list, plot their ID numbers and screen names in a table\n",
    "    Points: 4 \n",
    "  \n",
    "    -----------------------------------\n",
    "    Qestion 4:  Business question\n",
    "    Points: 20\n",
    "    -----------------------------------\n",
    "        Novelty: 10\n",
    "        Interestingness: 10\n",
    "    -----------------------------------\n",
    "    Run some additional experiments with your data to gain familiarity with the twitter data ant twitter API.  Come up with a business question and describe how Twitter data can help you answer that question.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "** Report: communicate the results**\n",
    "    Points: 20\n",
    "\n",
    "(1) What data you collected?\n",
    "    Points: 5 \n",
    "\n",
    "(2) Why this topic is interesting or important to you? (Motivations)\n",
    "    Points: 5 \n",
    "\n",
    "(3) How did you analyse the data?\n",
    "    Points: 5 \n",
    "\n",
    "(4) What did you find in the data?\n",
    "(please include figures or tables in the report, but no source code)\n",
    "    Points: 5 \n",
    "\n",
    "\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "** Slides (for 10 minutes of presentation): Story-telling **\n",
    "    Points: 20\n",
    "\n",
    "\n",
    "1. Motivation about the data collection, why the topic is interesting to you.\n",
    "    Points: 5 \n",
    "\n",
    "2. Communicating Results (figure/table)\n",
    "    Points: 10 \n",
    "\n",
    "3. Story telling (How all the parts (data, analysis, result) fit together as a story?)\n",
    "    Points: 5 \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
